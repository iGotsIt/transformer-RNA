{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import ExitStack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from torchmetrics.regression import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "#get device that we are using\n",
    "#torch.cuda.device_count()\n",
    "#torch.cuda.current_device()\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TCCGCACTTATGTACTGTGCTGAGATATAGTAGATTCTGCGTGTGATCGA',\n",
       "       'GTCTCGATCCACCGCTAGTAGTAAGACAACAGGGCTGCCTGGCTTCAACT',\n",
       "       'TGTTGGCCCAAGCTACTTCCGTTTACCAGAACCACAGTGTTAAGGGCTTC', ...,\n",
       "       'AACCTTGCTAGTGAACTGTGCCTCGTCGCGGTAATCCACGGAATATGTTG',\n",
       "       'TCTGGGGGTGGTCTCGTTCGAGTTTCCGGAGAATAGACTCGGCGGGTCCA',\n",
       "       'AGGATCCCCCCGACTAGTACTGAAGTAACCAGCTATTCCTGTTTGGCAGC'], dtype='<U50')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data processing\n",
    "with ExitStack() as stack:\n",
    "    data = sio.loadmat('Random.mat')\n",
    "\n",
    "    # Extract the data\n",
    "    C0 = np.array(data['C0'])\n",
    "    Seq = np.array(data['Seq'])\n",
    "    SS = np.array(data['SS'])\n",
    "Seq\n",
    "#data = np.concatenate((Seq, C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into test train\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    Seq, C0, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e\n",
    "\n",
    "class Vocabulary:\n",
    "    '''\n",
    "    __init__ is called when object is initiated, to initiate vocab dictionaries\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #initiate index to token dict\n",
    "        # PAD: padding to match sentence lengths\n",
    "        # SOS: start token\n",
    "        # EOS: end token\n",
    "        # UNK: words not found in the vocab \n",
    "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3:'<UNK>'}\n",
    "        #initiate token to index dict\n",
    "        self.stoi = {k:j for j,k in self.itos.items()} \n",
    "    \n",
    "    '''\n",
    "    __len__ used by dataloader to create batches (maybe need?)\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "        \n",
    "    '''tokenizer converts each character in RNA sequence to an element in a list'''\n",
    "    @staticmethod\n",
    "    def tokenizer(text, group_size):\n",
    "        #split sequences into sizes of the group size\n",
    "        tok_lower = text.lower()\n",
    "        return [tok_lower[i:i+group_size] for i in range(0, len(tok_lower), group_size)]\n",
    "    \n",
    "    #increase vocabulary size: go up to 4 depending on which is most popular --> divides evenly as well\n",
    "    '''build the vocab: map index to string, string to index'''\n",
    "    def build_vocab(self):\n",
    "        idx = 4 #start at 4 b/c 0 to 3 are taken\n",
    "        #5 letter residues\n",
    "        residues = [\"a\", \"t\", \"c\", \"g\"]\n",
    "        self.group_size = 5\n",
    "        for res1 in residues:\n",
    "            for res2 in residues:\n",
    "                for res3 in residues:\n",
    "                    for res4 in residues:\n",
    "                        for res5 in residues:\n",
    "                            group = res1+res2+res3+res4+res5\n",
    "                            self.stoi[group] = idx\n",
    "                            self.itos[idx] = group\n",
    "                            idx+=1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer(text, self.group_size)\n",
    "        numericalized_text = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.stoi.keys():\n",
    "                numericalized_text.append(self.stoi[token])\n",
    "            else:\n",
    "                numericalized_text.append(self.stoi['<UNK>'])\n",
    "        return numericalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1028"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_test = Vocabulary()\n",
    "v_test.build_vocab()\n",
    "v_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#Build Train Dataset#\n",
    "#####################\n",
    "\n",
    "class Train_Dataset(Dataset):\n",
    "    '''\n",
    "    Variables\n",
    "    x_train: training sequences\n",
    "    y_train: training flexibility index\n",
    "    transform: if we want to add augmentation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "        #create vocabulary (only for x data):\n",
    "        self.source_vocab = Vocabulary()\n",
    "        self.source_vocab.build_vocab()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    '''__getitem___ runs on 1 item at a time'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.x_train[index]\n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "        \n",
    "        #numericalize texts\n",
    "        numericalized_source = [self.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_source += self.source_vocab.numericalize(source_text)\n",
    "        numericalized_source.append(self.source_vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "        target = self.y_train[index][0]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(target, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation_Dataset(Dataset):\n",
    "    '''\n",
    "    Variables\n",
    "    x_train: training sequences\n",
    "    y_train: training flexibility index\n",
    "    transform: if we want to add augmentation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_dataset, x_test, y_test, transform=None):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    '''__getitem___ runs on 1 item at a time'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.x_test[index]\n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "        \n",
    "        #numericalize texts\n",
    "        numericalized_source = [self.train_dataset.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_source += self.train_dataset.source_vocab.numericalize(source_text)\n",
    "        numericalized_source.append(self.train_dataset.source_vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "        target = self.y_test[index][0]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(target, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#Collate#\n",
    "#########\n",
    "\n",
    "'''Adds padding (shouldn't need the mycollate function for this application)'''\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    #__call__: runs by default when MyCollate is created\n",
    "    def __call__(self, batch):\n",
    "        source = [item[0] for item in batch]\n",
    "        source = pad_sequence(source, batch_first=False, padding_value=self.pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader functions\n",
    "def get_train_loader(dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True): #increase num_workers according to CPU\n",
    "    #get pad_idx for collate fn\n",
    "    pad_idx = dataset.source_vocab.stoi['<PAD>']\n",
    "    #print(pad_idx)\n",
    "    #define loader\n",
    "    loader = DataLoader(dataset, batch_size = batch_size, num_workers = num_workers,\n",
    "                        shuffle=shuffle,\n",
    "                       pin_memory=pin_memory) \n",
    "    return loader\n",
    "\n",
    "def get_valid_loader(dataset, train_dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True):\n",
    "    pad_idx = train_dataset.source_vocab.stoi['<PAD>']\n",
    "    loader = DataLoader(dataset, batch_size = batch_size, num_workers = num_workers,\n",
    "                        shuffle=shuffle,\n",
    "                       pin_memory=pin_memory)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer adapted from https://n8henrie.com/2021/08/writing-a-transformer-classifier-in-pytorch/\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''https://pytorch.org/tutorials/beginner/transformer_tutorial.html'''\n",
    "\n",
    "    #vocab size is 8 i think\n",
    "    \n",
    "    #nvm i think vocab size needs to be larger than seq size: this way it can shrink down to the seq size\n",
    "    #positional encoder encodes a unique function for each index and position in the text\n",
    "    \n",
    "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(vocab_size, d_model)\n",
    "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float()\n",
    "            * (-math.log(10000.0)/d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 1::2] = torch.cos(position*div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRegressionModel(nn.Module):\n",
    "    '''text regression model using a transformer'''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            d_model,\n",
    "            n_head,\n",
    "            dim_feedforward,\n",
    "            num_layers,\n",
    "            dropout,\n",
    "            classifier_dropout,\n",
    "            activation = \"relu\"\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.vocab_size = vocab_size\n",
    "        assert d_model % n_head == 0 #assert that the number of attention heads divides into the size of the embedding (d_model)\n",
    "        \n",
    "        #may need to make vocab_size a bit bigger (same as encoding) for the embedding and encoding to work\n",
    "        self.emb = nn.Embedding(vocab_size, d_model) #embedding of size d_model\n",
    "        self.pos_encoder = PositionalEncoding(d_model, vocab_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.regressor = nn.Linear(d_model, 1)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.emb(x) * math.sqrt(self.d_model)\n",
    "        x=self.pos_encoder(x)\n",
    "        x=self.transformer_encoder(x)\n",
    "        x=x.mean(dim=1) #taking the mean along the sequence size dimension is a common way to process transformer output\n",
    "        x=self.regressor(x)\n",
    "        x=x.squeeze(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGCCTTCTTACTCTTACGCCCAGGGCATACGGGGGGTTCCCGATCGATG [0.27438]\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'aaaaa': 4, 'aaaat': 5, 'aaaac': 6, 'aaaag': 7, 'aaata': 8, 'aaatt': 9, 'aaatc': 10, 'aaatg': 11, 'aaaca': 12, 'aaact': 13, 'aaacc': 14, 'aaacg': 15, 'aaaga': 16, 'aaagt': 17, 'aaagc': 18, 'aaagg': 19, 'aataa': 20, 'aatat': 21, 'aatac': 22, 'aatag': 23, 'aatta': 24, 'aattt': 25, 'aattc': 26, 'aattg': 27, 'aatca': 28, 'aatct': 29, 'aatcc': 30, 'aatcg': 31, 'aatga': 32, 'aatgt': 33, 'aatgc': 34, 'aatgg': 35, 'aacaa': 36, 'aacat': 37, 'aacac': 38, 'aacag': 39, 'aacta': 40, 'aactt': 41, 'aactc': 42, 'aactg': 43, 'aacca': 44, 'aacct': 45, 'aaccc': 46, 'aaccg': 47, 'aacga': 48, 'aacgt': 49, 'aacgc': 50, 'aacgg': 51, 'aagaa': 52, 'aagat': 53, 'aagac': 54, 'aagag': 55, 'aagta': 56, 'aagtt': 57, 'aagtc': 58, 'aagtg': 59, 'aagca': 60, 'aagct': 61, 'aagcc': 62, 'aagcg': 63, 'aagga': 64, 'aaggt': 65, 'aaggc': 66, 'aaggg': 67, 'ataaa': 68, 'ataat': 69, 'ataac': 70, 'ataag': 71, 'atata': 72, 'atatt': 73, 'atatc': 74, 'atatg': 75, 'ataca': 76, 'atact': 77, 'atacc': 78, 'atacg': 79, 'ataga': 80, 'atagt': 81, 'atagc': 82, 'atagg': 83, 'attaa': 84, 'attat': 85, 'attac': 86, 'attag': 87, 'attta': 88, 'atttt': 89, 'atttc': 90, 'atttg': 91, 'attca': 92, 'attct': 93, 'attcc': 94, 'attcg': 95, 'attga': 96, 'attgt': 97, 'attgc': 98, 'attgg': 99, 'atcaa': 100, 'atcat': 101, 'atcac': 102, 'atcag': 103, 'atcta': 104, 'atctt': 105, 'atctc': 106, 'atctg': 107, 'atcca': 108, 'atcct': 109, 'atccc': 110, 'atccg': 111, 'atcga': 112, 'atcgt': 113, 'atcgc': 114, 'atcgg': 115, 'atgaa': 116, 'atgat': 117, 'atgac': 118, 'atgag': 119, 'atgta': 120, 'atgtt': 121, 'atgtc': 122, 'atgtg': 123, 'atgca': 124, 'atgct': 125, 'atgcc': 126, 'atgcg': 127, 'atgga': 128, 'atggt': 129, 'atggc': 130, 'atggg': 131, 'acaaa': 132, 'acaat': 133, 'acaac': 134, 'acaag': 135, 'acata': 136, 'acatt': 137, 'acatc': 138, 'acatg': 139, 'acaca': 140, 'acact': 141, 'acacc': 142, 'acacg': 143, 'acaga': 144, 'acagt': 145, 'acagc': 146, 'acagg': 147, 'actaa': 148, 'actat': 149, 'actac': 150, 'actag': 151, 'actta': 152, 'acttt': 153, 'acttc': 154, 'acttg': 155, 'actca': 156, 'actct': 157, 'actcc': 158, 'actcg': 159, 'actga': 160, 'actgt': 161, 'actgc': 162, 'actgg': 163, 'accaa': 164, 'accat': 165, 'accac': 166, 'accag': 167, 'accta': 168, 'acctt': 169, 'acctc': 170, 'acctg': 171, 'accca': 172, 'accct': 173, 'acccc': 174, 'acccg': 175, 'accga': 176, 'accgt': 177, 'accgc': 178, 'accgg': 179, 'acgaa': 180, 'acgat': 181, 'acgac': 182, 'acgag': 183, 'acgta': 184, 'acgtt': 185, 'acgtc': 186, 'acgtg': 187, 'acgca': 188, 'acgct': 189, 'acgcc': 190, 'acgcg': 191, 'acgga': 192, 'acggt': 193, 'acggc': 194, 'acggg': 195, 'agaaa': 196, 'agaat': 197, 'agaac': 198, 'agaag': 199, 'agata': 200, 'agatt': 201, 'agatc': 202, 'agatg': 203, 'agaca': 204, 'agact': 205, 'agacc': 206, 'agacg': 207, 'agaga': 208, 'agagt': 209, 'agagc': 210, 'agagg': 211, 'agtaa': 212, 'agtat': 213, 'agtac': 214, 'agtag': 215, 'agtta': 216, 'agttt': 217, 'agttc': 218, 'agttg': 219, 'agtca': 220, 'agtct': 221, 'agtcc': 222, 'agtcg': 223, 'agtga': 224, 'agtgt': 225, 'agtgc': 226, 'agtgg': 227, 'agcaa': 228, 'agcat': 229, 'agcac': 230, 'agcag': 231, 'agcta': 232, 'agctt': 233, 'agctc': 234, 'agctg': 235, 'agcca': 236, 'agcct': 237, 'agccc': 238, 'agccg': 239, 'agcga': 240, 'agcgt': 241, 'agcgc': 242, 'agcgg': 243, 'aggaa': 244, 'aggat': 245, 'aggac': 246, 'aggag': 247, 'aggta': 248, 'aggtt': 249, 'aggtc': 250, 'aggtg': 251, 'aggca': 252, 'aggct': 253, 'aggcc': 254, 'aggcg': 255, 'aggga': 256, 'agggt': 257, 'agggc': 258, 'agggg': 259, 'taaaa': 260, 'taaat': 261, 'taaac': 262, 'taaag': 263, 'taata': 264, 'taatt': 265, 'taatc': 266, 'taatg': 267, 'taaca': 268, 'taact': 269, 'taacc': 270, 'taacg': 271, 'taaga': 272, 'taagt': 273, 'taagc': 274, 'taagg': 275, 'tataa': 276, 'tatat': 277, 'tatac': 278, 'tatag': 279, 'tatta': 280, 'tattt': 281, 'tattc': 282, 'tattg': 283, 'tatca': 284, 'tatct': 285, 'tatcc': 286, 'tatcg': 287, 'tatga': 288, 'tatgt': 289, 'tatgc': 290, 'tatgg': 291, 'tacaa': 292, 'tacat': 293, 'tacac': 294, 'tacag': 295, 'tacta': 296, 'tactt': 297, 'tactc': 298, 'tactg': 299, 'tacca': 300, 'tacct': 301, 'taccc': 302, 'taccg': 303, 'tacga': 304, 'tacgt': 305, 'tacgc': 306, 'tacgg': 307, 'tagaa': 308, 'tagat': 309, 'tagac': 310, 'tagag': 311, 'tagta': 312, 'tagtt': 313, 'tagtc': 314, 'tagtg': 315, 'tagca': 316, 'tagct': 317, 'tagcc': 318, 'tagcg': 319, 'tagga': 320, 'taggt': 321, 'taggc': 322, 'taggg': 323, 'ttaaa': 324, 'ttaat': 325, 'ttaac': 326, 'ttaag': 327, 'ttata': 328, 'ttatt': 329, 'ttatc': 330, 'ttatg': 331, 'ttaca': 332, 'ttact': 333, 'ttacc': 334, 'ttacg': 335, 'ttaga': 336, 'ttagt': 337, 'ttagc': 338, 'ttagg': 339, 'tttaa': 340, 'tttat': 341, 'tttac': 342, 'tttag': 343, 'tttta': 344, 'ttttt': 345, 'ttttc': 346, 'ttttg': 347, 'tttca': 348, 'tttct': 349, 'tttcc': 350, 'tttcg': 351, 'tttga': 352, 'tttgt': 353, 'tttgc': 354, 'tttgg': 355, 'ttcaa': 356, 'ttcat': 357, 'ttcac': 358, 'ttcag': 359, 'ttcta': 360, 'ttctt': 361, 'ttctc': 362, 'ttctg': 363, 'ttcca': 364, 'ttcct': 365, 'ttccc': 366, 'ttccg': 367, 'ttcga': 368, 'ttcgt': 369, 'ttcgc': 370, 'ttcgg': 371, 'ttgaa': 372, 'ttgat': 373, 'ttgac': 374, 'ttgag': 375, 'ttgta': 376, 'ttgtt': 377, 'ttgtc': 378, 'ttgtg': 379, 'ttgca': 380, 'ttgct': 381, 'ttgcc': 382, 'ttgcg': 383, 'ttgga': 384, 'ttggt': 385, 'ttggc': 386, 'ttggg': 387, 'tcaaa': 388, 'tcaat': 389, 'tcaac': 390, 'tcaag': 391, 'tcata': 392, 'tcatt': 393, 'tcatc': 394, 'tcatg': 395, 'tcaca': 396, 'tcact': 397, 'tcacc': 398, 'tcacg': 399, 'tcaga': 400, 'tcagt': 401, 'tcagc': 402, 'tcagg': 403, 'tctaa': 404, 'tctat': 405, 'tctac': 406, 'tctag': 407, 'tctta': 408, 'tcttt': 409, 'tcttc': 410, 'tcttg': 411, 'tctca': 412, 'tctct': 413, 'tctcc': 414, 'tctcg': 415, 'tctga': 416, 'tctgt': 417, 'tctgc': 418, 'tctgg': 419, 'tccaa': 420, 'tccat': 421, 'tccac': 422, 'tccag': 423, 'tccta': 424, 'tcctt': 425, 'tcctc': 426, 'tcctg': 427, 'tccca': 428, 'tccct': 429, 'tcccc': 430, 'tcccg': 431, 'tccga': 432, 'tccgt': 433, 'tccgc': 434, 'tccgg': 435, 'tcgaa': 436, 'tcgat': 437, 'tcgac': 438, 'tcgag': 439, 'tcgta': 440, 'tcgtt': 441, 'tcgtc': 442, 'tcgtg': 443, 'tcgca': 444, 'tcgct': 445, 'tcgcc': 446, 'tcgcg': 447, 'tcgga': 448, 'tcggt': 449, 'tcggc': 450, 'tcggg': 451, 'tgaaa': 452, 'tgaat': 453, 'tgaac': 454, 'tgaag': 455, 'tgata': 456, 'tgatt': 457, 'tgatc': 458, 'tgatg': 459, 'tgaca': 460, 'tgact': 461, 'tgacc': 462, 'tgacg': 463, 'tgaga': 464, 'tgagt': 465, 'tgagc': 466, 'tgagg': 467, 'tgtaa': 468, 'tgtat': 469, 'tgtac': 470, 'tgtag': 471, 'tgtta': 472, 'tgttt': 473, 'tgttc': 474, 'tgttg': 475, 'tgtca': 476, 'tgtct': 477, 'tgtcc': 478, 'tgtcg': 479, 'tgtga': 480, 'tgtgt': 481, 'tgtgc': 482, 'tgtgg': 483, 'tgcaa': 484, 'tgcat': 485, 'tgcac': 486, 'tgcag': 487, 'tgcta': 488, 'tgctt': 489, 'tgctc': 490, 'tgctg': 491, 'tgcca': 492, 'tgcct': 493, 'tgccc': 494, 'tgccg': 495, 'tgcga': 496, 'tgcgt': 497, 'tgcgc': 498, 'tgcgg': 499, 'tggaa': 500, 'tggat': 501, 'tggac': 502, 'tggag': 503, 'tggta': 504, 'tggtt': 505, 'tggtc': 506, 'tggtg': 507, 'tggca': 508, 'tggct': 509, 'tggcc': 510, 'tggcg': 511, 'tggga': 512, 'tgggt': 513, 'tgggc': 514, 'tgggg': 515, 'caaaa': 516, 'caaat': 517, 'caaac': 518, 'caaag': 519, 'caata': 520, 'caatt': 521, 'caatc': 522, 'caatg': 523, 'caaca': 524, 'caact': 525, 'caacc': 526, 'caacg': 527, 'caaga': 528, 'caagt': 529, 'caagc': 530, 'caagg': 531, 'cataa': 532, 'catat': 533, 'catac': 534, 'catag': 535, 'catta': 536, 'cattt': 537, 'cattc': 538, 'cattg': 539, 'catca': 540, 'catct': 541, 'catcc': 542, 'catcg': 543, 'catga': 544, 'catgt': 545, 'catgc': 546, 'catgg': 547, 'cacaa': 548, 'cacat': 549, 'cacac': 550, 'cacag': 551, 'cacta': 552, 'cactt': 553, 'cactc': 554, 'cactg': 555, 'cacca': 556, 'cacct': 557, 'caccc': 558, 'caccg': 559, 'cacga': 560, 'cacgt': 561, 'cacgc': 562, 'cacgg': 563, 'cagaa': 564, 'cagat': 565, 'cagac': 566, 'cagag': 567, 'cagta': 568, 'cagtt': 569, 'cagtc': 570, 'cagtg': 571, 'cagca': 572, 'cagct': 573, 'cagcc': 574, 'cagcg': 575, 'cagga': 576, 'caggt': 577, 'caggc': 578, 'caggg': 579, 'ctaaa': 580, 'ctaat': 581, 'ctaac': 582, 'ctaag': 583, 'ctata': 584, 'ctatt': 585, 'ctatc': 586, 'ctatg': 587, 'ctaca': 588, 'ctact': 589, 'ctacc': 590, 'ctacg': 591, 'ctaga': 592, 'ctagt': 593, 'ctagc': 594, 'ctagg': 595, 'cttaa': 596, 'cttat': 597, 'cttac': 598, 'cttag': 599, 'cttta': 600, 'ctttt': 601, 'ctttc': 602, 'ctttg': 603, 'cttca': 604, 'cttct': 605, 'cttcc': 606, 'cttcg': 607, 'cttga': 608, 'cttgt': 609, 'cttgc': 610, 'cttgg': 611, 'ctcaa': 612, 'ctcat': 613, 'ctcac': 614, 'ctcag': 615, 'ctcta': 616, 'ctctt': 617, 'ctctc': 618, 'ctctg': 619, 'ctcca': 620, 'ctcct': 621, 'ctccc': 622, 'ctccg': 623, 'ctcga': 624, 'ctcgt': 625, 'ctcgc': 626, 'ctcgg': 627, 'ctgaa': 628, 'ctgat': 629, 'ctgac': 630, 'ctgag': 631, 'ctgta': 632, 'ctgtt': 633, 'ctgtc': 634, 'ctgtg': 635, 'ctgca': 636, 'ctgct': 637, 'ctgcc': 638, 'ctgcg': 639, 'ctgga': 640, 'ctggt': 641, 'ctggc': 642, 'ctggg': 643, 'ccaaa': 644, 'ccaat': 645, 'ccaac': 646, 'ccaag': 647, 'ccata': 648, 'ccatt': 649, 'ccatc': 650, 'ccatg': 651, 'ccaca': 652, 'ccact': 653, 'ccacc': 654, 'ccacg': 655, 'ccaga': 656, 'ccagt': 657, 'ccagc': 658, 'ccagg': 659, 'cctaa': 660, 'cctat': 661, 'cctac': 662, 'cctag': 663, 'cctta': 664, 'ccttt': 665, 'ccttc': 666, 'ccttg': 667, 'cctca': 668, 'cctct': 669, 'cctcc': 670, 'cctcg': 671, 'cctga': 672, 'cctgt': 673, 'cctgc': 674, 'cctgg': 675, 'cccaa': 676, 'cccat': 677, 'cccac': 678, 'cccag': 679, 'cccta': 680, 'ccctt': 681, 'ccctc': 682, 'ccctg': 683, 'cccca': 684, 'cccct': 685, 'ccccc': 686, 'ccccg': 687, 'cccga': 688, 'cccgt': 689, 'cccgc': 690, 'cccgg': 691, 'ccgaa': 692, 'ccgat': 693, 'ccgac': 694, 'ccgag': 695, 'ccgta': 696, 'ccgtt': 697, 'ccgtc': 698, 'ccgtg': 699, 'ccgca': 700, 'ccgct': 701, 'ccgcc': 702, 'ccgcg': 703, 'ccgga': 704, 'ccggt': 705, 'ccggc': 706, 'ccggg': 707, 'cgaaa': 708, 'cgaat': 709, 'cgaac': 710, 'cgaag': 711, 'cgata': 712, 'cgatt': 713, 'cgatc': 714, 'cgatg': 715, 'cgaca': 716, 'cgact': 717, 'cgacc': 718, 'cgacg': 719, 'cgaga': 720, 'cgagt': 721, 'cgagc': 722, 'cgagg': 723, 'cgtaa': 724, 'cgtat': 725, 'cgtac': 726, 'cgtag': 727, 'cgtta': 728, 'cgttt': 729, 'cgttc': 730, 'cgttg': 731, 'cgtca': 732, 'cgtct': 733, 'cgtcc': 734, 'cgtcg': 735, 'cgtga': 736, 'cgtgt': 737, 'cgtgc': 738, 'cgtgg': 739, 'cgcaa': 740, 'cgcat': 741, 'cgcac': 742, 'cgcag': 743, 'cgcta': 744, 'cgctt': 745, 'cgctc': 746, 'cgctg': 747, 'cgcca': 748, 'cgcct': 749, 'cgccc': 750, 'cgccg': 751, 'cgcga': 752, 'cgcgt': 753, 'cgcgc': 754, 'cgcgg': 755, 'cggaa': 756, 'cggat': 757, 'cggac': 758, 'cggag': 759, 'cggta': 760, 'cggtt': 761, 'cggtc': 762, 'cggtg': 763, 'cggca': 764, 'cggct': 765, 'cggcc': 766, 'cggcg': 767, 'cggga': 768, 'cgggt': 769, 'cgggc': 770, 'cgggg': 771, 'gaaaa': 772, 'gaaat': 773, 'gaaac': 774, 'gaaag': 775, 'gaata': 776, 'gaatt': 777, 'gaatc': 778, 'gaatg': 779, 'gaaca': 780, 'gaact': 781, 'gaacc': 782, 'gaacg': 783, 'gaaga': 784, 'gaagt': 785, 'gaagc': 786, 'gaagg': 787, 'gataa': 788, 'gatat': 789, 'gatac': 790, 'gatag': 791, 'gatta': 792, 'gattt': 793, 'gattc': 794, 'gattg': 795, 'gatca': 796, 'gatct': 797, 'gatcc': 798, 'gatcg': 799, 'gatga': 800, 'gatgt': 801, 'gatgc': 802, 'gatgg': 803, 'gacaa': 804, 'gacat': 805, 'gacac': 806, 'gacag': 807, 'gacta': 808, 'gactt': 809, 'gactc': 810, 'gactg': 811, 'gacca': 812, 'gacct': 813, 'gaccc': 814, 'gaccg': 815, 'gacga': 816, 'gacgt': 817, 'gacgc': 818, 'gacgg': 819, 'gagaa': 820, 'gagat': 821, 'gagac': 822, 'gagag': 823, 'gagta': 824, 'gagtt': 825, 'gagtc': 826, 'gagtg': 827, 'gagca': 828, 'gagct': 829, 'gagcc': 830, 'gagcg': 831, 'gagga': 832, 'gaggt': 833, 'gaggc': 834, 'gaggg': 835, 'gtaaa': 836, 'gtaat': 837, 'gtaac': 838, 'gtaag': 839, 'gtata': 840, 'gtatt': 841, 'gtatc': 842, 'gtatg': 843, 'gtaca': 844, 'gtact': 845, 'gtacc': 846, 'gtacg': 847, 'gtaga': 848, 'gtagt': 849, 'gtagc': 850, 'gtagg': 851, 'gttaa': 852, 'gttat': 853, 'gttac': 854, 'gttag': 855, 'gttta': 856, 'gtttt': 857, 'gtttc': 858, 'gtttg': 859, 'gttca': 860, 'gttct': 861, 'gttcc': 862, 'gttcg': 863, 'gttga': 864, 'gttgt': 865, 'gttgc': 866, 'gttgg': 867, 'gtcaa': 868, 'gtcat': 869, 'gtcac': 870, 'gtcag': 871, 'gtcta': 872, 'gtctt': 873, 'gtctc': 874, 'gtctg': 875, 'gtcca': 876, 'gtcct': 877, 'gtccc': 878, 'gtccg': 879, 'gtcga': 880, 'gtcgt': 881, 'gtcgc': 882, 'gtcgg': 883, 'gtgaa': 884, 'gtgat': 885, 'gtgac': 886, 'gtgag': 887, 'gtgta': 888, 'gtgtt': 889, 'gtgtc': 890, 'gtgtg': 891, 'gtgca': 892, 'gtgct': 893, 'gtgcc': 894, 'gtgcg': 895, 'gtgga': 896, 'gtggt': 897, 'gtggc': 898, 'gtggg': 899, 'gcaaa': 900, 'gcaat': 901, 'gcaac': 902, 'gcaag': 903, 'gcata': 904, 'gcatt': 905, 'gcatc': 906, 'gcatg': 907, 'gcaca': 908, 'gcact': 909, 'gcacc': 910, 'gcacg': 911, 'gcaga': 912, 'gcagt': 913, 'gcagc': 914, 'gcagg': 915, 'gctaa': 916, 'gctat': 917, 'gctac': 918, 'gctag': 919, 'gctta': 920, 'gcttt': 921, 'gcttc': 922, 'gcttg': 923, 'gctca': 924, 'gctct': 925, 'gctcc': 926, 'gctcg': 927, 'gctga': 928, 'gctgt': 929, 'gctgc': 930, 'gctgg': 931, 'gccaa': 932, 'gccat': 933, 'gccac': 934, 'gccag': 935, 'gccta': 936, 'gcctt': 937, 'gcctc': 938, 'gcctg': 939, 'gccca': 940, 'gccct': 941, 'gcccc': 942, 'gcccg': 943, 'gccga': 944, 'gccgt': 945, 'gccgc': 946, 'gccgg': 947, 'gcgaa': 948, 'gcgat': 949, 'gcgac': 950, 'gcgag': 951, 'gcgta': 952, 'gcgtt': 953, 'gcgtc': 954, 'gcgtg': 955, 'gcgca': 956, 'gcgct': 957, 'gcgcc': 958, 'gcgcg': 959, 'gcgga': 960, 'gcggt': 961, 'gcggc': 962, 'gcggg': 963, 'ggaaa': 964, 'ggaat': 965, 'ggaac': 966, 'ggaag': 967, 'ggata': 968, 'ggatt': 969, 'ggatc': 970, 'ggatg': 971, 'ggaca': 972, 'ggact': 973, 'ggacc': 974, 'ggacg': 975, 'ggaga': 976, 'ggagt': 977, 'ggagc': 978, 'ggagg': 979, 'ggtaa': 980, 'ggtat': 981, 'ggtac': 982, 'ggtag': 983, 'ggtta': 984, 'ggttt': 985, 'ggttc': 986, 'ggttg': 987, 'ggtca': 988, 'ggtct': 989, 'ggtcc': 990, 'ggtcg': 991, 'ggtga': 992, 'ggtgt': 993, 'ggtgc': 994, 'ggtgg': 995, 'ggcaa': 996, 'ggcat': 997, 'ggcac': 998, 'ggcag': 999, 'ggcta': 1000, 'ggctt': 1001, 'ggctc': 1002, 'ggctg': 1003, 'ggcca': 1004, 'ggcct': 1005, 'ggccc': 1006, 'ggccg': 1007, 'ggcga': 1008, 'ggcgt': 1009, 'ggcgc': 1010, 'ggcgg': 1011, 'gggaa': 1012, 'gggat': 1013, 'gggac': 1014, 'gggag': 1015, 'gggta': 1016, 'gggtt': 1017, 'gggtc': 1018, 'gggtg': 1019, 'gggca': 1020, 'gggct': 1021, 'gggcc': 1022, 'gggcg': 1023, 'gggga': 1024, 'ggggt': 1025, 'ggggc': 1026, 'ggggg': 1027}\n"
     ]
    }
   ],
   "source": [
    "train_data = Train_Dataset(x_train, y_train)\n",
    "print(x_train[0], y_train[0])\n",
    "train_data[0]\n",
    "\n",
    "print(train_data.source_vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGCGGCTGGAAGTAACCTACTCAAACATTGTGCATCCGCCTGGCTCGGGT [-0.56108] 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([  1, 755, 640, 212, 662, 388, 539, 485, 702, 509, 769,   2]),\n",
       " tensor(-0.5611))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = Validation_Dataset(train_data, x_test, y_test)\n",
    "print(x_test[0], y_test[0], len(x_test[0]))\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader(train_data, 32)\n",
    "source = next(iter(train_loader))[0]\n",
    "flex = next(iter(train_loader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_valid_loader(test_data, train_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = train_data.source_vocab.__len__()\n",
    "d_model = 100\n",
    "n_head = 5\n",
    "dim_feedforward = 2048\n",
    "num_layers = 6\n",
    "dropout = 0.1\n",
    "classifier_dropout = 0\n",
    "\n",
    "#create the model and then move it to the GPU\n",
    "model = TransformerRegressionModel(vocab_size, d_model, n_head, dim_feedforward, num_layers, dropout, classifier_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, target, accuracy_threshold):\n",
    "    num_correct = 0\n",
    "    for i in range(0, len(predictions)):\n",
    "        if abs(predictions[0].item() - target[0].item()) <= target[0].item()*accuracy_threshold:\n",
    "            num_correct+=1\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.SGD((p for p in model.parameters() if p.requires_grad), lr)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def train(model: nn.Module):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    total_num_correct = 0\n",
    "    #begin batching\n",
    "    for idx, batch in enumerate(iter(train_loader)):\n",
    "        predictions = model(batch[0].to(device))\n",
    "        scores = batch[1].to(device)\n",
    "\n",
    "        loss = criterion(predictions, scores)\n",
    "\n",
    "        #can add accuracy code, e.g. threshold within 10%; MSE is also a good indicator of correctness\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        #epoch_train_loss /= len(train_data)\n",
    "        \n",
    "        if idx == 349:\n",
    "            print(f\"{predictions=} | {scores=}\")\n",
    "    \n",
    "        batch_training_accuracy = accuracy(predictions, scores, 0.5)\n",
    "        total_num_correct += batch_training_accuracy\n",
    "\n",
    "    print(f\"{epoch_train_loss=}\")\n",
    "    train_accuracy = total_num_correct/len(train_data)\n",
    "    print(f\"{train_accuracy=}\")\n",
    "\n",
    "def evaluate(model: nn.Module):\n",
    "    model.eval()\n",
    "    epoch_test_loss = 0\n",
    "    total_num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(iter(test_loader)):\n",
    "            output = model(batch[0].to(device))\n",
    "            scores = batch[1].to(device)\n",
    "\n",
    "            test_loss = criterion(output, scores)\n",
    "            epoch_test_loss += test_loss.item()\n",
    "            #epoch_test_loss /= len(test_data)\n",
    "\n",
    "            batch_test_accuracy = accuracy(output, scores, 0.1)\n",
    "            total_num_correct += batch_test_accuracy\n",
    "\n",
    "    print(f\"{epoch_test_loss=}\")\n",
    "    test_accuracy = total_num_correct/len(test_data)\n",
    "    print(f\"{test_accuracy=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "epoch=1\n",
      "predictions=tensor([-0.1343, -0.1215, -0.0976, -0.1399, -0.1708, -0.1691, -0.2070, -0.1131,\n",
      "        -0.2253, -0.1661, -0.1640, -0.1372, -0.0976, -0.2061, -0.1270, -0.2098,\n",
      "        -0.1038, -0.1724, -0.1684, -0.1350, -0.1007, -0.1464, -0.1200, -0.1080,\n",
      "        -0.0992, -0.1161, -0.0778, -0.1527, -0.0884, -0.1370, -0.1472, -0.1156],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1185, -0.0751,  0.5645,  0.2053,  0.6346,  0.8052, -0.3633, -0.0565,\n",
      "         0.0566, -0.2292, -0.5742,  0.4107, -0.2909,  0.1708, -0.3644,  0.1310,\n",
      "         0.0635, -0.3925, -0.0120,  1.5859, -0.4495,  0.0812, -0.2380,  0.1042,\n",
      "        -0.2734,  0.1305,  0.2990, -0.2672, -0.3678, -0.1551, -0.3179, -0.1485],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.43332381546497\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.508541017770767\n",
      "test_accuracy=0.0\n",
      "elapsed=10.960482120513916\n",
      "epoch=2\n",
      "predictions=tensor([-0.2019, -0.1685, -0.1707, -0.1264, -0.1669, -0.2020, -0.1959, -0.1504,\n",
      "        -0.1837, -0.0248, -0.1367, -0.2332, -0.1906, -0.1221, -0.1205, -0.1434,\n",
      "        -0.1364, -0.1943, -0.1538, -0.1887, -0.0741, -0.1104, -0.1573, -0.2072,\n",
      "        -0.1678, -0.1240, -0.1448, -0.0852, -0.2087, -0.1671, -0.1394, -0.1083],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.7619,  0.1258, -0.6544, -0.3453, -0.4927,  0.2634, -0.7731, -0.3155,\n",
      "        -0.2690, -0.3459, -0.1387,  0.0196, -0.1514,  0.5699, -0.3362, -0.5965,\n",
      "        -0.6818, -0.3185, -0.4066, -0.5328, -0.2808,  0.0674, -0.1683,  0.3048,\n",
      "         0.0393,  0.1456, -0.2948,  0.0431, -0.3425, -0.4946,  0.0412, -0.4272],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.47631826996803\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.515685230493546\n",
      "test_accuracy=0.0\n",
      "elapsed=10.267797231674194\n",
      "epoch=3\n",
      "predictions=tensor([-0.1684, -0.1199, -0.1413, -0.1798, -0.1602, -0.2404, -0.2033, -0.1933,\n",
      "        -0.1741, -0.1755, -0.2207, -0.1742, -0.1492, -0.1396, -0.1890, -0.1170,\n",
      "        -0.2313, -0.1387, -0.1122, -0.1427, -0.0937, -0.1505, -0.2496, -0.1492,\n",
      "        -0.2533, -0.2207, -0.1635, -0.1944, -0.1744, -0.0975, -0.1421, -0.1338],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.3991, -0.2014, -0.0729, -0.1703, -0.0022,  0.6150,  0.3327,  0.1525,\n",
      "         0.2450,  0.1479, -0.0232,  0.0424, -0.3151,  0.0343, -0.4839, -0.3085,\n",
      "        -0.1266,  0.3785, -0.4797, -0.7018, -0.0462, -0.0381, -0.1966,  0.2359,\n",
      "        -0.4224, -0.0086, -0.3750, -0.6674, -0.1435,  0.6198, -0.2365, -0.1200],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.47722034156322\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.576848596334457\n",
      "test_accuracy=0.0\n",
      "elapsed=10.054502725601196\n",
      "epoch=4\n",
      "predictions=tensor([-0.1696, -0.1860, -0.2242, -0.2213, -0.2197, -0.2567, -0.1776, -0.1446,\n",
      "        -0.2218, -0.1454, -0.2020, -0.1321, -0.1118, -0.2342, -0.1675, -0.2228,\n",
      "        -0.2159, -0.1365, -0.0913, -0.2358, -0.2157, -0.1751, -0.1882, -0.2046,\n",
      "        -0.2152, -0.1640, -0.1748, -0.1646, -0.1908, -0.1994, -0.2392, -0.2467],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3207, -0.1840, -0.2564,  0.0632, -0.2318, -0.3106, -0.3841,  0.3064,\n",
      "        -0.7412,  0.3670, -0.4982, -0.0153, -0.4917, -0.3063,  0.2420, -0.5659,\n",
      "        -0.1878, -0.0386,  0.6774,  0.1878, -0.6749, -0.2824, -0.9908, -0.3567,\n",
      "         0.0183, -0.4105, -0.1345, -0.2163, -0.1540,  0.0812, -0.2475, -0.5333],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.37661205232143\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.579587861895561\n",
      "test_accuracy=0.0\n",
      "elapsed=9.689566135406494\n",
      "epoch=5\n",
      "predictions=tensor([-0.3032, -0.1297, -0.1477, -0.2449, -0.1337, -0.1711, -0.1648, -0.1458,\n",
      "        -0.1748, -0.2407, -0.2153, -0.1217, -0.2052, -0.1374, -0.2103, -0.1438,\n",
      "        -0.1737, -0.2128, -0.1118, -0.2176,  0.0066, -0.2551, -0.1597, -0.1694,\n",
      "        -0.1391, -0.1300, -0.2843, -0.1296, -0.1951, -0.1019, -0.2339, -0.1595],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4017,  0.0104, -0.4533, -0.6156, -0.4277,  0.5050,  0.8055,  0.0810,\n",
      "        -0.3521, -0.2391,  0.6977, -0.4222,  0.1630, -0.5841, -0.0079,  0.4599,\n",
      "         0.2474, -0.8011,  0.5244, -0.2708, -0.2409, -0.0067, -0.5320, -0.1941,\n",
      "         0.2037, -0.3975, -0.2166, -0.4188, -0.3994, -0.4674, -0.2647,  0.0314],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.49188715219498\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.48082411289215\n",
      "test_accuracy=0.0\n",
      "elapsed=10.087165355682373\n",
      "epoch=6\n",
      "predictions=tensor([-0.0745, -0.1406, -0.1885, -0.1347, -0.1866, -0.1086, -0.1143, -0.2021,\n",
      "        -0.2332, -0.1528, -0.1198, -0.1190, -0.1758, -0.0952, -0.1644, -0.1448,\n",
      "        -0.2034, -0.0939, -0.0850, -0.1631, -0.2572, -0.1799, -0.2027, -0.2204,\n",
      "        -0.1397, -0.1609, -0.1282, -0.2256, -0.1595, -0.1414, -0.1577, -0.1130],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2094,  0.1528, -0.6823,  0.0552, -0.3300,  0.1509, -0.4615,  0.1428,\n",
      "        -0.2806,  0.0232, -0.3078, -0.5989, -0.8206,  0.5093,  0.2247, -0.5298,\n",
      "        -0.3726, -0.4919, -0.2492,  0.3513, -0.3528, -0.2206, -0.2039,  0.1556,\n",
      "        -0.3179, -0.4691,  0.3366,  0.7623, -0.3449,  0.1284, -0.0022,  0.3439],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.3787337988615\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.54529957473278\n",
      "test_accuracy=0.0\n",
      "elapsed=9.95555329322815\n",
      "epoch=7\n",
      "predictions=tensor([-0.1914, -0.0438, -0.1971, -0.1029, -0.1802, -0.0635, -0.1341, -0.1782,\n",
      "        -0.0993, -0.1694, -0.0244, -0.1159, -0.1040, -0.1409, -0.1975, -0.2152,\n",
      "        -0.1139, -0.1599, -0.1510, -0.0767, -0.0931, -0.1721, -0.1336, -0.1751,\n",
      "        -0.1584, -0.1415, -0.1429, -0.1480, -0.1278, -0.1178, -0.1241, -0.2033],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1620,  0.3617, -0.5586,  0.0112, -0.5365,  0.2989,  0.0165, -0.0952,\n",
      "         0.4107, -0.0127, -0.3689, -0.0672,  0.3589,  0.3052, -0.3877, -0.4803,\n",
      "        -0.0550,  0.2875, -0.3104,  0.1982,  1.1050, -0.2511,  0.4143, -0.5460,\n",
      "        -0.4363, -0.4038,  0.2495, -0.3611, -0.0478, -0.4800, -0.1670, -0.2973],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=100.1498609483242\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=11.529586896300316\n",
      "test_accuracy=0.0\n",
      "elapsed=10.306545972824097\n",
      "epoch=8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4012/1563521053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{epoch=}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mepoch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4012/1168852673.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jeffe\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_coef_clamped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-overload]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train the model!\n",
    "epochs = 50\n",
    "\n",
    "print(\"starting\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"{epoch=}\")\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    evaluate(model)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(f\"{elapsed=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "train_iter = iter(IMDB(split='train'))\n",
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : torch.Size([32])\n",
      "1 : torch.Size([32])\n",
      "2 : torch.Size([32])\n",
      "3 : torch.Size([32])\n",
      "4 : torch.Size([32])\n",
      "5 : torch.Size([32])\n",
      "6 : torch.Size([32])\n",
      "7 : torch.Size([32])\n",
      "8 : torch.Size([32])\n",
      "9 : torch.Size([32])\n",
      "10 : torch.Size([32])\n",
      "11 : torch.Size([32])\n",
      "12 : torch.Size([32])\n",
      "13 : torch.Size([32])\n",
      "14 : torch.Size([32])\n",
      "15 : torch.Size([32])\n",
      "16 : torch.Size([32])\n",
      "17 : torch.Size([32])\n",
      "18 : torch.Size([32])\n",
      "19 : torch.Size([32])\n",
      "20 : torch.Size([32])\n",
      "21 : torch.Size([32])\n",
      "22 : torch.Size([32])\n",
      "23 : torch.Size([32])\n",
      "24 : torch.Size([32])\n",
      "25 : torch.Size([32])\n",
      "26 : torch.Size([32])\n",
      "27 : torch.Size([32])\n",
      "28 : torch.Size([32])\n",
      "29 : torch.Size([32])\n",
      "30 : torch.Size([32])\n",
      "31 : torch.Size([32])\n",
      "32 : torch.Size([32])\n",
      "33 : torch.Size([32])\n",
      "34 : torch.Size([32])\n",
      "35 : torch.Size([32])\n",
      "36 : torch.Size([32])\n",
      "37 : torch.Size([32])\n",
      "38 : torch.Size([32])\n",
      "39 : torch.Size([32])\n",
      "40 : torch.Size([32])\n",
      "41 : torch.Size([32])\n",
      "42 : torch.Size([32])\n",
      "43 : torch.Size([32])\n",
      "44 : torch.Size([32])\n",
      "45 : torch.Size([32])\n",
      "46 : torch.Size([32])\n",
      "47 : torch.Size([32])\n",
      "48 : torch.Size([32])\n",
      "49 : torch.Size([32])\n",
      "50 : torch.Size([32])\n",
      "51 : torch.Size([32])\n",
      "52 : torch.Size([32])\n",
      "53 : torch.Size([32])\n",
      "54 : torch.Size([32])\n",
      "55 : torch.Size([32])\n",
      "56 : torch.Size([32])\n",
      "57 : torch.Size([32])\n",
      "58 : torch.Size([32])\n",
      "59 : torch.Size([32])\n",
      "60 : torch.Size([32])\n",
      "61 : torch.Size([32])\n",
      "62 : torch.Size([32])\n",
      "63 : torch.Size([32])\n",
      "64 : torch.Size([32])\n",
      "65 : torch.Size([32])\n",
      "66 : torch.Size([32])\n",
      "67 : torch.Size([32])\n",
      "68 : torch.Size([32])\n",
      "69 : torch.Size([32])\n",
      "70 : torch.Size([32])\n",
      "71 : torch.Size([32])\n",
      "72 : torch.Size([32])\n",
      "73 : torch.Size([32])\n",
      "74 : torch.Size([32])\n",
      "75 : torch.Size([32])\n",
      "76 : torch.Size([32])\n",
      "77 : torch.Size([32])\n",
      "78 : torch.Size([32])\n",
      "79 : torch.Size([32])\n",
      "80 : torch.Size([32])\n",
      "81 : torch.Size([32])\n",
      "82 : torch.Size([32])\n",
      "83 : torch.Size([32])\n",
      "84 : torch.Size([32])\n",
      "85 : torch.Size([32])\n",
      "86 : torch.Size([32])\n",
      "87 : torch.Size([32])\n",
      "88 : torch.Size([32])\n",
      "89 : torch.Size([32])\n",
      "90 : torch.Size([32])\n",
      "91 : torch.Size([32])\n",
      "92 : torch.Size([32])\n",
      "93 : torch.Size([32])\n",
      "94 : torch.Size([32])\n",
      "95 : torch.Size([32])\n",
      "96 : torch.Size([32])\n",
      "97 : torch.Size([32])\n",
      "98 : torch.Size([32])\n",
      "99 : torch.Size([32])\n",
      "100 : torch.Size([32])\n",
      "101 : torch.Size([32])\n",
      "102 : torch.Size([32])\n",
      "103 : torch.Size([32])\n",
      "104 : torch.Size([32])\n",
      "105 : torch.Size([32])\n",
      "106 : torch.Size([32])\n",
      "107 : torch.Size([32])\n",
      "108 : torch.Size([32])\n",
      "109 : torch.Size([32])\n",
      "110 : torch.Size([32])\n",
      "111 : torch.Size([32])\n",
      "112 : torch.Size([32])\n",
      "113 : torch.Size([32])\n",
      "114 : torch.Size([32])\n",
      "115 : torch.Size([32])\n",
      "116 : torch.Size([32])\n",
      "117 : torch.Size([32])\n",
      "118 : torch.Size([32])\n",
      "119 : torch.Size([32])\n",
      "120 : torch.Size([32])\n",
      "121 : torch.Size([32])\n",
      "122 : torch.Size([32])\n",
      "123 : torch.Size([32])\n",
      "124 : torch.Size([32])\n",
      "125 : torch.Size([32])\n",
      "126 : torch.Size([32])\n",
      "127 : torch.Size([32])\n",
      "128 : torch.Size([32])\n",
      "129 : torch.Size([32])\n",
      "130 : torch.Size([32])\n",
      "131 : torch.Size([32])\n",
      "132 : torch.Size([32])\n",
      "133 : torch.Size([32])\n",
      "134 : torch.Size([32])\n",
      "135 : torch.Size([32])\n",
      "136 : torch.Size([32])\n",
      "137 : torch.Size([32])\n",
      "138 : torch.Size([32])\n",
      "139 : torch.Size([32])\n",
      "140 : torch.Size([32])\n",
      "141 : torch.Size([32])\n",
      "142 : torch.Size([32])\n",
      "143 : torch.Size([32])\n",
      "144 : torch.Size([32])\n",
      "145 : torch.Size([32])\n",
      "146 : torch.Size([32])\n",
      "147 : torch.Size([32])\n",
      "148 : torch.Size([32])\n",
      "149 : torch.Size([32])\n",
      "150 : torch.Size([32])\n",
      "151 : torch.Size([32])\n",
      "152 : torch.Size([32])\n",
      "153 : torch.Size([32])\n",
      "154 : torch.Size([32])\n",
      "155 : torch.Size([32])\n",
      "156 : torch.Size([32])\n",
      "157 : torch.Size([32])\n",
      "158 : torch.Size([32])\n",
      "159 : torch.Size([32])\n",
      "160 : torch.Size([32])\n",
      "161 : torch.Size([32])\n",
      "162 : torch.Size([32])\n",
      "163 : torch.Size([32])\n",
      "164 : torch.Size([32])\n",
      "165 : torch.Size([32])\n",
      "166 : torch.Size([32])\n",
      "167 : torch.Size([32])\n",
      "168 : torch.Size([32])\n",
      "169 : torch.Size([32])\n",
      "170 : torch.Size([32])\n",
      "171 : torch.Size([32])\n",
      "172 : torch.Size([32])\n",
      "173 : torch.Size([32])\n",
      "174 : torch.Size([32])\n",
      "175 : torch.Size([32])\n",
      "176 : torch.Size([32])\n",
      "177 : torch.Size([32])\n",
      "178 : torch.Size([32])\n",
      "179 : torch.Size([32])\n",
      "180 : torch.Size([32])\n",
      "181 : torch.Size([32])\n",
      "182 : torch.Size([32])\n",
      "183 : torch.Size([32])\n",
      "184 : torch.Size([32])\n",
      "185 : torch.Size([32])\n",
      "186 : torch.Size([32])\n",
      "187 : torch.Size([32])\n",
      "188 : torch.Size([32])\n",
      "189 : torch.Size([32])\n",
      "190 : torch.Size([32])\n",
      "191 : torch.Size([32])\n",
      "192 : torch.Size([32])\n",
      "193 : torch.Size([32])\n",
      "194 : torch.Size([32])\n",
      "195 : torch.Size([32])\n",
      "196 : torch.Size([32])\n",
      "197 : torch.Size([32])\n",
      "198 : torch.Size([32])\n",
      "199 : torch.Size([32])\n",
      "200 : torch.Size([32])\n",
      "201 : torch.Size([32])\n",
      "202 : torch.Size([32])\n",
      "203 : torch.Size([32])\n",
      "204 : torch.Size([32])\n",
      "205 : torch.Size([32])\n",
      "206 : torch.Size([32])\n",
      "207 : torch.Size([32])\n",
      "208 : torch.Size([32])\n",
      "209 : torch.Size([32])\n",
      "210 : torch.Size([32])\n",
      "211 : torch.Size([32])\n",
      "212 : torch.Size([32])\n",
      "213 : torch.Size([32])\n",
      "214 : torch.Size([32])\n",
      "215 : torch.Size([32])\n",
      "216 : torch.Size([32])\n",
      "217 : torch.Size([32])\n",
      "218 : torch.Size([32])\n",
      "219 : torch.Size([32])\n",
      "220 : torch.Size([32])\n",
      "221 : torch.Size([32])\n",
      "222 : torch.Size([32])\n",
      "223 : torch.Size([32])\n",
      "224 : torch.Size([32])\n",
      "225 : torch.Size([32])\n",
      "226 : torch.Size([32])\n",
      "227 : torch.Size([32])\n",
      "228 : torch.Size([32])\n",
      "229 : torch.Size([32])\n",
      "230 : torch.Size([32])\n",
      "231 : torch.Size([32])\n",
      "232 : torch.Size([32])\n",
      "233 : torch.Size([32])\n",
      "234 : torch.Size([32])\n",
      "235 : torch.Size([32])\n",
      "236 : torch.Size([32])\n",
      "237 : torch.Size([32])\n",
      "238 : torch.Size([32])\n",
      "239 : torch.Size([32])\n",
      "240 : torch.Size([32])\n",
      "241 : torch.Size([32])\n",
      "242 : torch.Size([32])\n",
      "243 : torch.Size([32])\n",
      "244 : torch.Size([32])\n",
      "245 : torch.Size([32])\n",
      "246 : torch.Size([32])\n",
      "247 : torch.Size([32])\n",
      "248 : torch.Size([32])\n",
      "249 : torch.Size([32])\n",
      "250 : torch.Size([32])\n",
      "251 : torch.Size([32])\n",
      "252 : torch.Size([32])\n",
      "253 : torch.Size([32])\n",
      "254 : torch.Size([32])\n",
      "255 : torch.Size([32])\n",
      "256 : torch.Size([32])\n",
      "257 : torch.Size([32])\n",
      "258 : torch.Size([32])\n",
      "259 : torch.Size([32])\n",
      "260 : torch.Size([32])\n",
      "261 : torch.Size([32])\n",
      "262 : torch.Size([32])\n",
      "263 : torch.Size([32])\n",
      "264 : torch.Size([32])\n",
      "265 : torch.Size([32])\n",
      "266 : torch.Size([32])\n",
      "267 : torch.Size([32])\n",
      "268 : torch.Size([32])\n",
      "269 : torch.Size([32])\n",
      "270 : torch.Size([32])\n",
      "271 : torch.Size([32])\n",
      "272 : torch.Size([32])\n",
      "273 : torch.Size([32])\n",
      "274 : torch.Size([32])\n",
      "275 : torch.Size([32])\n",
      "276 : torch.Size([32])\n",
      "277 : torch.Size([32])\n",
      "278 : torch.Size([32])\n",
      "279 : torch.Size([32])\n",
      "280 : torch.Size([32])\n",
      "281 : torch.Size([32])\n",
      "282 : torch.Size([32])\n",
      "283 : torch.Size([32])\n",
      "284 : torch.Size([32])\n",
      "285 : torch.Size([32])\n",
      "286 : torch.Size([32])\n",
      "287 : torch.Size([32])\n",
      "288 : torch.Size([32])\n",
      "289 : torch.Size([32])\n",
      "290 : torch.Size([32])\n",
      "291 : torch.Size([32])\n",
      "292 : torch.Size([32])\n",
      "293 : torch.Size([32])\n",
      "294 : torch.Size([32])\n",
      "295 : torch.Size([32])\n",
      "296 : torch.Size([32])\n",
      "297 : torch.Size([32])\n",
      "298 : torch.Size([32])\n",
      "299 : torch.Size([32])\n",
      "300 : torch.Size([32])\n",
      "301 : torch.Size([32])\n",
      "302 : torch.Size([32])\n",
      "303 : torch.Size([32])\n",
      "304 : torch.Size([32])\n",
      "305 : torch.Size([32])\n",
      "306 : torch.Size([32])\n",
      "307 : torch.Size([32])\n",
      "308 : torch.Size([32])\n",
      "309 : torch.Size([32])\n",
      "310 : torch.Size([32])\n",
      "311 : torch.Size([32])\n",
      "312 : torch.Size([32])\n",
      "313 : torch.Size([32])\n",
      "314 : torch.Size([32])\n",
      "315 : torch.Size([32])\n",
      "316 : torch.Size([32])\n",
      "317 : torch.Size([32])\n",
      "318 : torch.Size([32])\n",
      "319 : torch.Size([32])\n",
      "320 : torch.Size([32])\n",
      "321 : torch.Size([32])\n",
      "322 : torch.Size([32])\n",
      "323 : torch.Size([32])\n",
      "324 : torch.Size([32])\n",
      "325 : torch.Size([32])\n",
      "326 : torch.Size([32])\n",
      "327 : torch.Size([32])\n",
      "328 : torch.Size([32])\n",
      "329 : torch.Size([32])\n",
      "330 : torch.Size([32])\n",
      "331 : torch.Size([32])\n",
      "332 : torch.Size([32])\n",
      "333 : torch.Size([32])\n",
      "334 : torch.Size([32])\n",
      "335 : torch.Size([32])\n",
      "336 : torch.Size([32])\n",
      "337 : torch.Size([32])\n",
      "338 : torch.Size([32])\n",
      "339 : torch.Size([32])\n",
      "340 : torch.Size([32])\n",
      "341 : torch.Size([32])\n",
      "342 : torch.Size([32])\n",
      "343 : torch.Size([32])\n",
      "344 : torch.Size([32])\n",
      "345 : torch.Size([32])\n",
      "346 : torch.Size([32])\n",
      "347 : torch.Size([32])\n",
      "348 : torch.Size([32])\n",
      "349 : torch.Size([32])\n",
      "350 : torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(iter(train_loader)):\n",
    "   print(idx, \":\", batch[1].size())\n",
    "\n",
    "#for target in next(iter(train_loader))[1]:\n",
    "#    print(target.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
