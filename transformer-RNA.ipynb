{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from contextlib import ExitStack\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics.regression import MeanSquaredError\n",
    "from torchmetrics.regression import R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "#get device that we are using\n",
    "#torch.cuda.device_count()\n",
    "#torch.cuda.current_device()\n",
    "#torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TCCGCACTTATGTACTGTGCTGAGATATAGTAGATTCTGCGTGTGATCGA',\n",
       "       'GTCTCGATCCACCGCTAGTAGTAAGACAACAGGGCTGCCTGGCTTCAACT',\n",
       "       'TGTTGGCCCAAGCTACTTCCGTTTACCAGAACCACAGTGTTAAGGGCTTC', ...,\n",
       "       'AACCTTGCTAGTGAACTGTGCCTCGTCGCGGTAATCCACGGAATATGTTG',\n",
       "       'TCTGGGGGTGGTCTCGTTCGAGTTTCCGGAGAATAGACTCGGCGGGTCCA',\n",
       "       'AGGATCCCCCCGACTAGTACTGAAGTAACCAGCTATTCCTGTTTGGCAGC'], dtype='<U50')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data processing\n",
    "with ExitStack() as stack:\n",
    "    data = sio.loadmat('Random.mat')\n",
    "\n",
    "    # Extract the data\n",
    "    C0 = np.array(data['C0'])\n",
    "    Seq = np.array(data['Seq'])\n",
    "    SS = np.array(data['SS'])\n",
    "Seq\n",
    "#data = np.concatenate((Seq, C0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into test train\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    Seq, C0, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://towardsdatascience.com/custom-datasets-in-pytorch-part-2-text-machine-translation-71c41a3e994e\n",
    "\n",
    "class Vocabulary:\n",
    "    '''\n",
    "    __init__ is called when object is initiated, to initiate vocab dictionaries\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        #initiate index to token dict\n",
    "        # PAD: padding to match sentence lengths\n",
    "        # SOS: start token\n",
    "        # EOS: end token\n",
    "        # UNK: words not found in the vocab \n",
    "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3:'<UNK>'}\n",
    "        #initiate token to index dict\n",
    "        self.stoi = {k:j for j,k in self.itos.items()} \n",
    "    \n",
    "    '''\n",
    "    __len__ used by dataloader to create batches (maybe need?)\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    '''tokenizer converts each character in RNA sequence to an element in a list'''\n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower() for tok in text]\n",
    "    \n",
    "\n",
    "    #increase vocabulary size: go up to 4 depending on which is most popular --> divides evenly as well\n",
    "    '''build the vocab: map index to string, string to index'''\n",
    "    def build_vocab(self):\n",
    "        \n",
    "        idx = 4 #start at 4 b/c 0 to 3 are taken\n",
    "        #single letter residues\n",
    "        residues = [\"a\", \"t\", \"c\", \"g\"]\n",
    "        for res in residues:\n",
    "            self.stoi[res] = idx\n",
    "            self.itos[idx] = res\n",
    "            idx+=1\n",
    "\n",
    "    def numericalize(self, text):\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        numericalized_text = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.stoi.keys():\n",
    "                numericalized_text.append(self.stoi[token])\n",
    "            else:\n",
    "                numericalized_text.append(self.stoi['<UNK>'])\n",
    "        return numericalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_test = Vocabulary()\n",
    "v_test.build_vocab()\n",
    "v_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#Build Train Dataset#\n",
    "#####################\n",
    "\n",
    "class Train_Dataset(Dataset):\n",
    "    '''\n",
    "    Variables\n",
    "    x_train: training sequences\n",
    "    y_train: training flexibility index\n",
    "    transform: if we want to add augmentation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, x_train, y_train, transform=None):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.transform = transform\n",
    "\n",
    "        #create vocabulary (only for x data):\n",
    "        self.source_vocab = Vocabulary()\n",
    "        self.source_vocab.build_vocab()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    '''__getitem___ runs on 1 item at a time'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.x_train[index]\n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "        \n",
    "        #numericalize texts\n",
    "        numericalized_source = [self.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_source += self.source_vocab.numericalize(source_text)\n",
    "        numericalized_source.append(self.source_vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "        target = self.y_train[index][0]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(target, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation_Dataset(Dataset):\n",
    "    '''\n",
    "    Variables\n",
    "    x_train: training sequences\n",
    "    y_train: training flexibility index\n",
    "    transform: if we want to add augmentation\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_dataset, x_test, y_test, transform=None):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_test)\n",
    "    \n",
    "    '''__getitem___ runs on 1 item at a time'''\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.x_test[index]\n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "        \n",
    "        #numericalize texts\n",
    "        numericalized_source = [self.train_dataset.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numericalized_source += self.train_dataset.source_vocab.numericalize(source_text)\n",
    "        numericalized_source.append(self.train_dataset.source_vocab.stoi[\"<EOS>\"])\n",
    "\n",
    "        target = self.y_test[index][0]\n",
    "\n",
    "        return torch.tensor(numericalized_source), torch.tensor(target, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#Collate#\n",
    "#########\n",
    "\n",
    "'''Adds padding (shouldn't need the mycollate function for this application)'''\n",
    "class MyCollate:\n",
    "    def __init__(self, pad_idx):\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    #__call__: runs by default when MyCollate is created\n",
    "    def __call__(self, batch):\n",
    "        source = [item[0] for item in batch]\n",
    "        source = pad_sequence(source, batch_first=False, padding_value=self.pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader functions\n",
    "def get_train_loader(dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True): #increase num_workers according to CPU\n",
    "    #get pad_idx for collate fn\n",
    "    pad_idx = dataset.source_vocab.stoi['<PAD>']\n",
    "    #print(pad_idx)\n",
    "    #define loader\n",
    "    loader = DataLoader(dataset, batch_size = batch_size, num_workers = num_workers,\n",
    "                        shuffle=shuffle,\n",
    "                       pin_memory=pin_memory) \n",
    "    return loader\n",
    "\n",
    "def get_valid_loader(dataset, train_dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True):\n",
    "    pad_idx = train_dataset.source_vocab.stoi['<PAD>']\n",
    "    loader = DataLoader(dataset, batch_size = batch_size, num_workers = num_workers,\n",
    "                        shuffle=shuffle,\n",
    "                       pin_memory=pin_memory)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer adapted from https://n8henrie.com/2021/08/writing-a-transformer-classifier-in-pytorch/\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    '''https://pytorch.org/tutorials/beginner/transformer_tutorial.html'''\n",
    "\n",
    "    #vocab size is 8 i think\n",
    "    \n",
    "    #nvm i think vocab size needs to be larger than seq size: this way it can shrink down to the seq size\n",
    "    #positional encoder encodes a unique function for each index and position in the text\n",
    "    \n",
    "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(vocab_size, d_model)\n",
    "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float()\n",
    "            * (-math.log(10000.0)/d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position*div_term)\n",
    "        pe[:, 1::2] = torch.cos(position*div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerRegressionModel(nn.Module):\n",
    "    '''text regression model using a transformer'''\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            vocab_size,\n",
    "            d_model,\n",
    "            n_head,\n",
    "            dim_feedforward,\n",
    "            num_layers,\n",
    "            dropout,\n",
    "            classifier_dropout,\n",
    "            activation = \"relu\"\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.vocab_size = vocab_size\n",
    "        assert d_model % n_head == 0 #assert that the number of attention heads divides into the size of the embedding (d_model)\n",
    "        \n",
    "        #may need to make vocab_size a bit bigger (same as encoding) for the embedding and encoding to work\n",
    "        self.emb = nn.Embedding(vocab_size, d_model) #embedding of size d_model\n",
    "        self.pos_encoder = PositionalEncoding(d_model, vocab_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.regressor = nn.Linear(d_model, 1)\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x=self.emb(x) * math.sqrt(self.d_model)\n",
    "        x=self.pos_encoder(x)\n",
    "        x=self.transformer_encoder(x)\n",
    "        x=x.mean(dim=1) #taking the mean along the sequence size dimension is a common way to process transformer output\n",
    "        x=self.regressor(x)\n",
    "        x=x.squeeze(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAGCCTTCTTACTCTTACGCCCAGGGCATACGGGGGGTTCCCGATCGATG [0.27438]\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'a': 4, 't': 5, 'c': 6, 'g': 7}\n"
     ]
    }
   ],
   "source": [
    "train_data = Train_Dataset(x_train, y_train)\n",
    "print(x_train[0], y_train[0])\n",
    "train_data[0]\n",
    "\n",
    "print(train_data.source_vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CGCGGCTGGAAGTAACCTACTCAAACATTGTGCATCCGCCTGGCTCGGGT [-0.56108]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 6, 7, 6, 7, 7, 6, 5, 7, 7, 4, 4, 7, 5, 4, 4, 6, 6, 5, 4, 6, 5, 6, 4,\n",
       "         4, 4, 6, 4, 5, 5, 7, 5, 7, 6, 4, 5, 6, 6, 7, 6, 6, 5, 7, 7, 6, 5, 6, 7,\n",
       "         7, 7, 5, 2]),\n",
       " tensor(-0.5611))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = Validation_Dataset(train_data, x_test, y_test)\n",
    "print(x_test[0], y_test[0])\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_train_loader(train_data, 32)\n",
    "source = next(iter(train_loader))[0]\n",
    "flex = next(iter(train_loader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_valid_loader(test_data, train_data, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = train_data.source_vocab.__len__()\n",
    "d_model = 200\n",
    "n_head = 2\n",
    "dim_feedforward = 200\n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "classifier_dropout = 0\n",
    "\n",
    "#create the model and then move it to the GPU\n",
    "model = TransformerRegressionModel(vocab_size, d_model, n_head, dim_feedforward, num_layers, dropout, classifier_dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, target, accuracy_threshold):\n",
    "    num_correct = 0\n",
    "    for i in range(0, len(predictions)):\n",
    "        if abs(predictions[0].item() - target[0].item()) <= target[0].item()*accuracy_threshold:\n",
    "            num_correct+=1\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.002\n",
    "optimizer = torch.optim.SGD((p for p in model.parameters() if p.requires_grad), lr)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def train(model: nn.Module):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "\n",
    "    total_num_correct = 0\n",
    "    #begin batching\n",
    "    for idx, batch in enumerate(iter(train_loader)):\n",
    "        predictions = model(batch[0].to(device))\n",
    "        scores = batch[1].to(device)\n",
    "\n",
    "        loss = criterion(predictions, scores)\n",
    "\n",
    "        #can add accuracy code, e.g. threshold within 10%; MSE is also a good indicator of correctness\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "        #epoch_train_loss /= len(train_data)\n",
    "        \n",
    "        if idx == 349:\n",
    "            print(f\"{predictions=} | {scores=}\")\n",
    "    \n",
    "        batch_training_accuracy = accuracy(predictions, scores, 0.5)\n",
    "        total_num_correct += batch_training_accuracy\n",
    "\n",
    "    print(f\"{epoch_train_loss=}\")\n",
    "    train_accuracy = total_num_correct/len(train_data)\n",
    "    print(f\"{train_accuracy=}\")\n",
    "\n",
    "def evaluate(model: nn.Module):\n",
    "    model.eval()\n",
    "    epoch_test_loss = 0\n",
    "    total_num_correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(iter(test_loader)):\n",
    "            output = model(batch[0].to(device))\n",
    "            scores = batch[1].to(device)\n",
    "\n",
    "            test_loss = criterion(output, scores)\n",
    "            epoch_test_loss += test_loss.item()\n",
    "            #epoch_test_loss /= len(test_data)\n",
    "\n",
    "            batch_test_accuracy = accuracy(output, scores, 0.1)\n",
    "            total_num_correct += batch_test_accuracy\n",
    "\n",
    "    print(f\"{epoch_test_loss=}\")\n",
    "    test_accuracy = total_num_correct/len(test_data)\n",
    "    print(f\"{test_accuracy=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "epoch=1\n",
      "predictions=tensor([-0.1512, -0.0457, -0.0558, -0.0812, -0.1009, -0.0756, -0.0894, -0.0580,\n",
      "        -0.1231, -0.1134, -0.1424, -0.0750, -0.0722, -0.0183, -0.1006, -0.1032,\n",
      "        -0.1277, -0.1183, -0.1034, -0.0740, -0.1256, -0.1593, -0.1048, -0.0622,\n",
      "        -0.0438, -0.0954, -0.0870, -0.0167, -0.1311, -0.0459, -0.1347, -0.1366],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1185, -0.0751,  0.5645,  0.2053,  0.6346,  0.8052, -0.3633, -0.0565,\n",
      "         0.0566, -0.2292, -0.5742,  0.4107, -0.2909,  0.1708, -0.3644,  0.1310,\n",
      "         0.0635, -0.3925, -0.0120,  1.5859, -0.4495,  0.0812, -0.2380,  0.1042,\n",
      "        -0.2734,  0.1305,  0.2990, -0.2672, -0.3678, -0.1551, -0.3179, -0.1485],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=55.95057813823223\n",
      "train_accuracy=0.011404133998574484\n",
      "epoch_test_loss=6.021609216928482\n",
      "test_accuracy=0.0\n",
      "elapsed=7.004184007644653\n",
      "epoch=2\n",
      "predictions=tensor([-0.0735, -0.0834, -0.1006, -0.0845, -0.0921, -0.0981, -0.1045, -0.0376,\n",
      "        -0.1791, -0.1026, -0.0689,  0.0016, -0.0723, -0.0887, -0.0485, -0.0641,\n",
      "        -0.0866, -0.0648, -0.1474, -0.1054, -0.0555, -0.1055, -0.0969, -0.1060,\n",
      "        -0.1168, -0.0119, -0.1315, -0.0690, -0.0479, -0.0423, -0.0657, -0.1251],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.7619,  0.1258, -0.6544, -0.3453, -0.4927,  0.2634, -0.7731, -0.3155,\n",
      "        -0.2690, -0.3459, -0.1387,  0.0196, -0.1514,  0.5699, -0.3362, -0.5965,\n",
      "        -0.6818, -0.3185, -0.4066, -0.5328, -0.2808,  0.0674, -0.1683,  0.3048,\n",
      "         0.0393,  0.1456, -0.2948,  0.0431, -0.3425, -0.4946,  0.0412, -0.4272],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.88922346383333\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=6.091119855642319\n",
      "test_accuracy=0.0\n",
      "elapsed=6.305388927459717\n",
      "epoch=3\n",
      "predictions=tensor([-0.1561, -0.1466, -0.1013, -0.1345, -0.1534, -0.2398, -0.1075, -0.1618,\n",
      "        -0.1395, -0.2031, -0.1448, -0.1373, -0.2063, -0.2021, -0.1389, -0.0903,\n",
      "        -0.1249, -0.1223, -0.1366, -0.1692, -0.1271, -0.1188, -0.0668, -0.1777,\n",
      "        -0.1879, -0.1025, -0.0690, -0.1277, -0.0774, -0.0505, -0.1114, -0.1074],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.3991, -0.2014, -0.0729, -0.1703, -0.0022,  0.6150,  0.3327,  0.1525,\n",
      "         0.2450,  0.1479, -0.0232,  0.0424, -0.3151,  0.0343, -0.4839, -0.3085,\n",
      "        -0.1266,  0.3785, -0.4797, -0.7018, -0.0462, -0.0381, -0.1966,  0.2359,\n",
      "        -0.4224, -0.0086, -0.3750, -0.6674, -0.1435,  0.6198, -0.2365, -0.1200],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.5801046192646\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.873570166528225\n",
      "test_accuracy=0.0\n",
      "elapsed=6.302786827087402\n",
      "epoch=4\n",
      "predictions=tensor([-0.1480, -0.1816, -0.1761, -0.0925, -0.1309, -0.1581, -0.0645, -0.1316,\n",
      "        -0.1635, -0.1132, -0.1644, -0.1953, -0.1123, -0.2315, -0.1319, -0.1549,\n",
      "        -0.1869, -0.1324, -0.1658, -0.0320, -0.1031, -0.1299, -0.1793, -0.1960,\n",
      "        -0.1502, -0.1465, -0.1797, -0.1272, -0.0675, -0.0945, -0.1681, -0.1594],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3207, -0.1840, -0.2564,  0.0632, -0.2318, -0.3106, -0.3841,  0.3064,\n",
      "        -0.7412,  0.3670, -0.4982, -0.0153, -0.4917, -0.3063,  0.2420, -0.5659,\n",
      "        -0.1878, -0.0386,  0.6774,  0.1878, -0.6749, -0.2824, -0.9908, -0.3567,\n",
      "         0.0183, -0.4105, -0.1345, -0.2163, -0.1540,  0.0812, -0.2475, -0.5333],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.57332446798682\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.74590165913105\n",
      "test_accuracy=0.0\n",
      "elapsed=6.31270170211792\n",
      "epoch=5\n",
      "predictions=tensor([-0.1391, -0.0968, -0.1190, -0.1178, -0.0923, -0.1082, -0.1243, -0.1584,\n",
      "        -0.0815, -0.1398, -0.1331, -0.0512, -0.1134, -0.0910, -0.0731, -0.0698,\n",
      "        -0.1235, -0.2021, -0.0534, -0.1219, -0.1310, -0.1366, -0.1523, -0.0367,\n",
      "        -0.0634, -0.0634, -0.0546, -0.0739, -0.0958, -0.1739, -0.0736, -0.1627],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4017,  0.0104, -0.4533, -0.6156, -0.4277,  0.5050,  0.8055,  0.0810,\n",
      "        -0.3521, -0.2391,  0.6977, -0.4222,  0.1630, -0.5841, -0.0079,  0.4599,\n",
      "         0.2474, -0.8011,  0.5244, -0.2708, -0.2409, -0.0067, -0.5320, -0.1941,\n",
      "         0.2037, -0.3975, -0.2166, -0.4188, -0.3994, -0.4674, -0.2647,  0.0314],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.656891856342554\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.920457564294338\n",
      "test_accuracy=0.0\n",
      "elapsed=6.263415336608887\n",
      "epoch=6\n",
      "predictions=tensor([-0.1619, -0.1712, -0.1016, -0.1020, -0.0774, -0.1102, -0.1326, -0.1293,\n",
      "        -0.1051, -0.1491, -0.1034, -0.1179, -0.1872, -0.1047, -0.1714, -0.1632,\n",
      "        -0.1457, -0.1359, -0.0939, -0.1713, -0.1705, -0.1536, -0.1531, -0.1120,\n",
      "        -0.1580, -0.1409, -0.1166, -0.1371, -0.1666, -0.0818, -0.1441, -0.1443],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2094,  0.1528, -0.6823,  0.0552, -0.3300,  0.1509, -0.4615,  0.1428,\n",
      "        -0.2806,  0.0232, -0.3078, -0.5989, -0.8206,  0.5093,  0.2247, -0.5298,\n",
      "        -0.3726, -0.4919, -0.2492,  0.3513, -0.3528, -0.2206, -0.2039,  0.1556,\n",
      "        -0.3179, -0.4691,  0.3366,  0.7623, -0.3449,  0.1284, -0.0022,  0.3439],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.593145456165075\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.995628587901592\n",
      "test_accuracy=0.0\n",
      "elapsed=6.206166982650757\n",
      "epoch=7\n",
      "predictions=tensor([-0.0705, -0.0790, -0.1031, -0.0121, -0.1028, -0.0505, -0.0256, -0.0483,\n",
      "        -0.1073, -0.1336, -0.0428, -0.0773, -0.1541, -0.1514, -0.1082, -0.0826,\n",
      "        -0.0439, -0.1116, -0.0868, -0.0658, -0.1116, -0.0903, -0.0643, -0.0505,\n",
      "        -0.0563, -0.0728, -0.1022, -0.0767, -0.0613, -0.0533, -0.0519, -0.0396],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1620,  0.3617, -0.5586,  0.0112, -0.5365,  0.2989,  0.0165, -0.0952,\n",
      "         0.4107, -0.0127, -0.3689, -0.0672,  0.3589,  0.3052, -0.3877, -0.4803,\n",
      "        -0.0550,  0.2875, -0.3104,  0.1982,  1.1050, -0.2511,  0.4143, -0.5460,\n",
      "        -0.4363, -0.4038,  0.2495, -0.3611, -0.0478, -0.4800, -0.1670, -0.2973],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.48497964814305\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.64218507707119\n",
      "test_accuracy=0.0\n",
      "elapsed=6.710042953491211\n",
      "epoch=8\n",
      "predictions=tensor([-0.1258, -0.1426, -0.1578, -0.1392, -0.1752, -0.1521, -0.1309, -0.1412,\n",
      "        -0.0866, -0.1357, -0.1390, -0.1773, -0.1437, -0.1560, -0.1491, -0.1163,\n",
      "        -0.0728, -0.1567, -0.1200, -0.1436, -0.1343, -0.0962, -0.1453, -0.0584,\n",
      "        -0.1371, -0.0703, -0.1617, -0.1602, -0.1299, -0.1850, -0.1083, -0.1250],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.3406, -0.3816, -0.1706, -0.4657, -0.1986, -0.0965, -0.5333,  0.5080,\n",
      "        -0.3104,  0.0631,  0.5056, -0.6623,  0.1679, -0.0651,  0.6508, -0.4784,\n",
      "        -0.1981,  0.1664, -0.1014, -0.2544, -0.4158, -0.1865, -0.3910, -0.1122,\n",
      "        -0.6632,  0.4033, -0.3955,  0.7428,  0.1410, -0.0057,  0.5321, -0.1623],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.62738782912493\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.747998625040054\n",
      "test_accuracy=0.0\n",
      "elapsed=7.265018701553345\n",
      "epoch=9\n",
      "predictions=tensor([-0.1149, -0.1425, -0.1044, -0.0882, -0.0892, -0.1338, -0.1420, -0.1563,\n",
      "        -0.1328, -0.0746, -0.1034, -0.1315, -0.1234, -0.0488, -0.0936, -0.1419,\n",
      "        -0.1588, -0.0563, -0.1287, -0.1445, -0.0943, -0.1458, -0.1178, -0.1781,\n",
      "        -0.1152, -0.1485, -0.1024, -0.1088, -0.1103, -0.1733, -0.1052, -0.0779],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1103,  0.0050, -0.0441,  0.1508, -0.2123, -0.4293,  0.1192, -0.0889,\n",
      "         0.4997, -0.6032, -0.1416, -0.0990,  0.0358, -0.1823, -0.1202, -0.1308,\n",
      "        -0.4252,  0.5070, -0.6637, -0.2037,  0.7940, -0.1906, -0.8385, -0.9657,\n",
      "        -0.4367, -0.3634, -0.1001, -0.5792, -0.1380, -0.3669, -0.4823, -0.1628],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.62053308263421\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.807772614061832\n",
      "test_accuracy=0.0\n",
      "elapsed=9.060204029083252\n",
      "epoch=10\n",
      "predictions=tensor([-0.1087, -0.1742, -0.0752, -0.1236, -0.1685, -0.1099, -0.1252, -0.1213,\n",
      "        -0.1317, -0.1198, -0.1291, -0.1065, -0.1069, -0.1841, -0.1425, -0.1539,\n",
      "        -0.1413, -0.1207, -0.1000, -0.1200, -0.1600, -0.1511, -0.1350, -0.1508,\n",
      "        -0.1461, -0.1371, -0.1622, -0.0720, -0.1267, -0.1756, -0.1536, -0.1147],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3565, -0.4116, -0.0984, -0.5507, -0.3884, -0.2983, -0.8037, -0.1837,\n",
      "        -0.3787,  0.2851, -0.4383, -0.5900,  0.1207, -0.0780,  0.0700,  0.1225,\n",
      "        -0.5752, -0.4051, -0.5803, -0.1762, -0.1486,  0.2991, -0.2844,  0.0671,\n",
      "        -0.3568, -0.3046, -0.2390, -0.2041, -0.3993, -0.6059, -0.3532, -0.3201],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.482486478984356\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.819065198302269\n",
      "test_accuracy=0.0\n",
      "elapsed=8.440193176269531\n",
      "epoch=11\n",
      "predictions=tensor([-0.1420, -0.1615, -0.1407, -0.1111, -0.0601, -0.0659, -0.1602, -0.1385,\n",
      "        -0.1525, -0.0719, -0.1204, -0.1254, -0.1250, -0.1349, -0.1075, -0.1500,\n",
      "        -0.1524, -0.1011, -0.1076, -0.1725, -0.1037, -0.1678, -0.1576, -0.0834,\n",
      "        -0.0899, -0.0898, -0.1275, -0.1127, -0.1390, -0.1429, -0.0955, -0.1129],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4738,  0.0592, -0.3515, -1.2017, -0.0336,  1.2799,  0.2326, -0.6682,\n",
      "        -0.5239, -0.1776, -0.3768,  0.2109, -0.3734, -0.3935,  0.4155, -0.2112,\n",
      "        -0.4777, -0.1835, -0.5557, -0.0372, -0.2330, -0.4941, -0.3400, -0.0110,\n",
      "        -0.6408, -0.0707,  0.2491, -0.4611, -0.3582,  0.2251, -0.1600, -0.3536],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.44760448113084\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.808987967669964\n",
      "test_accuracy=0.0\n",
      "elapsed=8.600055932998657\n",
      "epoch=12\n",
      "predictions=tensor([-0.1206, -0.1007, -0.0828, -0.1239, -0.1650, -0.1330, -0.0847, -0.1028,\n",
      "        -0.0805, -0.0875, -0.0999, -0.0526, -0.1565, -0.0777, -0.1137, -0.0742,\n",
      "        -0.1680, -0.1402, -0.1358, -0.1300, -0.1312, -0.0680, -0.1255, -0.1466,\n",
      "        -0.0972, -0.1444, -0.0660, -0.0861, -0.0835, -0.0700, -0.1284, -0.1027],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5569,  0.0945, -0.4267, -0.2073,  0.2860, -0.4224,  0.0361, -0.2185,\n",
      "        -0.0030,  0.0014, -0.1681, -0.0846, -0.2180, -0.1970, -0.3059, -0.5557,\n",
      "         0.0999,  0.0652, -0.2646, -0.4072, -0.9908, -0.4952, -0.3971, -0.6756,\n",
      "         0.7837, -0.1873, -0.4446,  0.0848, -0.2025, -0.2655,  0.5227, -0.0407],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.28288158029318\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.758192524313927\n",
      "test_accuracy=0.0\n",
      "elapsed=8.054845094680786\n",
      "epoch=13\n",
      "predictions=tensor([-0.1581, -0.1820, -0.0798, -0.1261, -0.1644, -0.1035, -0.1050, -0.0968,\n",
      "        -0.2020, -0.1374, -0.0979, -0.1601, -0.1471, -0.0398, -0.0903, -0.0628,\n",
      "        -0.1274, -0.0743, -0.1350, -0.1415, -0.1211, -0.0997, -0.1106, -0.1166,\n",
      "        -0.0777, -0.1416, -0.1492, -0.1117, -0.1079, -0.1032, -0.1304, -0.1574],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5031, -0.0257,  0.3100, -0.0396,  0.4141,  0.7298, -0.3224, -0.1152,\n",
      "         0.1217,  0.0993, -0.0965, -0.1228,  0.2364,  0.0702, -0.1906,  0.7134,\n",
      "         0.1484, -0.4035, -0.2214,  0.3289, -0.5224,  0.1544, -0.2879,  0.3753,\n",
      "        -0.2840, -0.2555, -0.4493,  0.4858,  0.2810, -0.2674, -0.1431, -0.0708],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.397130221128464\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.748687654733658\n",
      "test_accuracy=0.0\n",
      "elapsed=6.391357421875\n",
      "epoch=14\n",
      "predictions=tensor([-0.1564, -0.1424, -0.1299, -0.2145, -0.1917, -0.1222, -0.2129, -0.1687,\n",
      "        -0.1759, -0.1627, -0.1315, -0.1676, -0.1160, -0.1318, -0.1353, -0.1137,\n",
      "        -0.1172, -0.0997, -0.1052, -0.1616, -0.1253, -0.1553, -0.1972, -0.1248,\n",
      "        -0.1039, -0.1575, -0.1821, -0.0925, -0.1373, -0.1542, -0.1494, -0.1424],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.0058,  0.2942, -0.4438, -0.4522, -0.4562, -0.2092, -0.0234, -0.6847,\n",
      "         1.0574, -0.5583, -0.0651, -0.6137, -0.1658, -0.1572, -0.0120, -0.5118,\n",
      "        -0.0370, -0.1995, -0.2989, -0.5612, -0.0232, -0.8527,  0.5504, -0.1386,\n",
      "        -0.3820, -0.3565, -0.1019,  0.0159, -0.1925, -0.4582, -0.3975, -0.3106],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.45689204335213\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.959920309484005\n",
      "test_accuracy=0.0\n",
      "elapsed=6.691337585449219\n",
      "epoch=15\n",
      "predictions=tensor([-0.1088, -0.0684, -0.1057, -0.0777, -0.1056, -0.1194, -0.0869, -0.1136,\n",
      "        -0.1103, -0.1158, -0.0518, -0.1880, -0.1469, -0.1309, -0.0340, -0.1136,\n",
      "        -0.1306, -0.1015, -0.1311, -0.1459, -0.1499, -0.1930, -0.1566, -0.0895,\n",
      "        -0.1036, -0.1281, -0.1601, -0.1169, -0.0970, -0.1360, -0.1730, -0.1227],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.5530, -0.2636, -0.4674, -0.1781,  0.0502, -0.0670, -0.3823, -0.0851,\n",
      "        -0.9204, -0.0205,  0.4386, -0.1860,  0.1483,  0.2212,  0.2758, -0.3352,\n",
      "        -0.7133,  0.5316, -0.3724, -0.5389,  0.0838, -0.4262,  0.0255, -0.4236,\n",
      "        -0.1003, -0.2620, -0.4421, -0.2396, -0.2496, -0.4172, -0.6208,  0.2216],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.57193526625633\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.778104819357395\n",
      "test_accuracy=0.0\n",
      "elapsed=6.376285076141357\n",
      "epoch=16\n",
      "predictions=tensor([-0.1568, -0.1310, -0.1195, -0.1263, -0.1072, -0.1694, -0.1081, -0.1510,\n",
      "        -0.1429, -0.1204, -0.1207, -0.1597, -0.1619, -0.0866, -0.1993, -0.1651,\n",
      "        -0.1626, -0.1161, -0.1470, -0.0984, -0.1263, -0.0982, -0.1259, -0.0951,\n",
      "        -0.1309, -0.1477, -0.1209, -0.1482, -0.1485, -0.1979, -0.1899, -0.1229],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1437, -0.3334,  0.0927, -0.4536, -0.7717, -0.2925, -0.3673, -0.5920,\n",
      "         0.1288, -0.3255,  0.3100, -0.6192,  0.2572, -0.2475, -0.3884,  0.1207,\n",
      "        -0.5279, -0.4336,  0.0789, -0.0392,  0.0126, -0.2247,  0.0104, -0.0662,\n",
      "        -0.4807,  0.1876, -0.1459, -0.6395, -0.5082, -0.5159,  0.0813,  0.4974],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.356356613337994\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.749487359076738\n",
      "test_accuracy=0.0\n",
      "elapsed=7.275020360946655\n",
      "epoch=17\n",
      "predictions=tensor([-0.1525, -0.1318, -0.1719, -0.1597, -0.1827, -0.1452, -0.1739, -0.1606,\n",
      "        -0.1762, -0.1711, -0.1643, -0.1563, -0.1381, -0.1300, -0.1328, -0.1278,\n",
      "        -0.1939, -0.1011, -0.1032, -0.1476, -0.1382, -0.1055, -0.1416, -0.1590,\n",
      "        -0.1778, -0.1492, -0.1968, -0.1383, -0.1645, -0.1524, -0.1478, -0.1280],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1312, -0.0336,  0.1579, -0.1599,  0.4371, -0.3653, -0.7463,  0.0761,\n",
      "         0.0593,  0.1285, -0.6682, -0.5210,  0.8247, -0.5747, -0.0579, -0.4278,\n",
      "        -0.4838,  0.5014,  0.6679, -0.3207, -0.3796, -0.1186,  0.4707, -0.0139,\n",
      "        -0.1025,  0.8120, -0.3412,  0.7276,  0.0789,  0.6744,  0.0612,  0.2342],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.192909963428974\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.79784432798624\n",
      "test_accuracy=0.0\n",
      "elapsed=7.243143320083618\n",
      "epoch=18\n",
      "predictions=tensor([-0.1331, -0.1175, -0.1420, -0.1331, -0.1583, -0.1610, -0.1262, -0.1614,\n",
      "        -0.1418, -0.1402, -0.1265, -0.1330, -0.0978, -0.1225, -0.1144, -0.1852,\n",
      "        -0.1717, -0.1817, -0.1677, -0.0657, -0.1325, -0.1308, -0.1036, -0.0572,\n",
      "        -0.1393, -0.0698, -0.1970, -0.0802, -0.1276, -0.1197, -0.1269, -0.1961],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.0511, -0.2310,  0.2964,  0.5905,  0.1043,  0.3667, -0.1621,  0.1417,\n",
      "        -0.4654,  0.0944, -0.4711, -0.3772, -0.0482, -0.1427, -0.0396,  0.2870,\n",
      "         0.2548, -0.0204,  0.2446, -0.6643,  0.4338, -0.3158, -0.2266, -0.3197,\n",
      "        -0.0858,  0.1775,  0.2058,  0.8620, -0.5030, -0.3627, -0.1789, -0.3281],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.35915690660477\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.798059701919556\n",
      "test_accuracy=0.0\n",
      "elapsed=7.254268169403076\n",
      "epoch=19\n",
      "predictions=tensor([-0.0922, -0.1292, -0.0938, -0.1451, -0.0995, -0.2052, -0.1577, -0.1385,\n",
      "        -0.0968, -0.1302, -0.1293, -0.2060, -0.0893, -0.1528, -0.1347, -0.1682,\n",
      "        -0.1464, -0.1470, -0.1162, -0.1418, -0.1230, -0.0903, -0.1075, -0.1486,\n",
      "        -0.0937, -0.1521, -0.1472, -0.1766, -0.2024, -0.1472, -0.1570, -0.1416],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1777,  0.2986, -0.3412,  0.0783, -0.1023,  0.0990, -0.5028, -0.5798,\n",
      "         0.0248, -0.4927, -0.7133, -0.3994, -0.0776, -0.3206, -0.1684, -0.3918,\n",
      "         0.3991, -0.2427, -0.3819, -0.3916, -0.5243, -0.0661, -0.1605,  0.0469,\n",
      "        -0.4881, -0.4773, -0.4580,  0.3104,  0.3080,  0.1401,  0.0627,  0.2681],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.477392699569464\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.9752470925450325\n",
      "test_accuracy=0.0\n",
      "elapsed=7.330138683319092\n",
      "epoch=20\n",
      "predictions=tensor([-0.0267, -0.0943, -0.1551, -0.1393, -0.0651, -0.1010, -0.1133, -0.1340,\n",
      "        -0.1362, -0.1191, -0.1346, -0.1012, -0.1219, -0.1256, -0.1653, -0.0879,\n",
      "        -0.1147, -0.0958, -0.1336, -0.0994, -0.1328, -0.1533, -0.1366, -0.1499,\n",
      "        -0.1247, -0.1283, -0.1754, -0.1359, -0.1038, -0.0417, -0.1247, -0.1173],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5742,  0.0322, -0.9108, -0.8290, -0.1726, -0.0316,  0.0596, -0.1210,\n",
      "        -0.1594,  0.5100, -0.3886, -0.3412, -0.3063, -0.3777, -0.6523, -0.2208,\n",
      "        -0.4747,  0.4947, -0.3931, -0.1529,  0.4715, -0.3789,  0.2171, -0.4038,\n",
      "        -0.1511,  0.0234, -0.5908,  0.0604,  0.1143,  0.2560, -0.3429,  0.0821],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.3690166734159\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.768641211092472\n",
      "test_accuracy=0.0\n",
      "elapsed=7.250438213348389\n",
      "epoch=21\n",
      "predictions=tensor([-0.1033, -0.1018, -0.0988, -0.1055, -0.0266, -0.0824, -0.0630, -0.0733,\n",
      "        -0.0622, -0.0642, -0.1208, -0.1798, -0.0721, -0.1107, -0.0883, -0.0872,\n",
      "        -0.1625, -0.0804, -0.0807, -0.0519, -0.1251, -0.1229, -0.1024, -0.1468,\n",
      "        -0.1083, -0.1107, -0.1399, -0.0817, -0.1175, -0.1279, -0.0818, -0.1072],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1812,  0.3684,  0.0225, -0.0198,  0.1441, -0.4655,  0.1867,  0.0080,\n",
      "        -0.1984, -0.2279, -0.0232, -0.2594, -0.5429,  0.4372,  0.3568, -0.4284,\n",
      "         0.0092,  0.2250, -0.1706, -0.5757,  0.5816,  0.1831,  0.0332, -0.1449,\n",
      "        -0.4660, -0.0830,  0.1759, -0.4816,  0.1671, -0.1719,  0.1272,  0.7390],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.473686784505844\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.672526717185974\n",
      "test_accuracy=0.0\n",
      "elapsed=7.37759256362915\n",
      "epoch=22\n",
      "predictions=tensor([-0.0891, -0.1383, -0.1220, -0.1040, -0.1113, -0.1341, -0.0633, -0.0852,\n",
      "        -0.1213, -0.0747, -0.0628, -0.0423, -0.1616, -0.1383, -0.1001, -0.1191,\n",
      "        -0.1213, -0.1350, -0.0444, -0.1253, -0.1329, -0.0772, -0.1282, -0.0952,\n",
      "        -0.1185, -0.0604, -0.0749, -0.0628, -0.0920, -0.1008, -0.1305, -0.1298],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3819, -0.1906,  0.0699,  0.0412, -0.4046, -0.1658, -0.1340,  0.2405,\n",
      "        -0.5417, -0.5787,  0.0431, -0.2880,  0.7930, -0.1927, -0.2663, -0.3900,\n",
      "        -0.2380, -0.2026, -0.4809, -0.2489,  0.0587, -0.8015, -0.3047, -0.2856,\n",
      "         0.9964,  0.0982,  0.6627, -0.3740,  0.0400,  0.0716,  0.2201, -0.2787],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.568471133708954\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.659598544239998\n",
      "test_accuracy=0.0\n",
      "elapsed=7.586098909378052\n",
      "epoch=23\n",
      "predictions=tensor([-0.1277, -0.0887, -0.1029, -0.1262, -0.1341, -0.1101, -0.1508, -0.0813,\n",
      "        -0.1094, -0.1117, -0.1414, -0.1285, -0.1073, -0.1317, -0.0646, -0.1097,\n",
      "        -0.1786, -0.1276, -0.1080, -0.1399, -0.1019, -0.1558, -0.1008, -0.1850,\n",
      "        -0.0887, -0.1308, -0.0988, -0.1222, -0.1326, -0.0678, -0.0830, -0.1060],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-1.8161e-01, -2.9988e-01, -2.2639e-01, -8.1574e-02, -1.7307e-01,\n",
      "        -1.9601e-01, -4.8808e-01, -6.5444e-01,  7.4892e-02,  1.5701e-01,\n",
      "        -6.7685e-01, -1.4757e-01,  9.6808e-02, -4.6381e-02,  5.5622e-01,\n",
      "         2.8041e-01, -5.7814e-01, -6.4000e-04, -8.1868e-01, -6.8338e-01,\n",
      "         1.2322e-01, -3.3872e-01,  5.3384e-01,  4.3701e-02, -4.1852e-02,\n",
      "         2.2542e-01, -5.1522e-01, -5.1457e-01, -1.3964e-01, -2.3113e-01,\n",
      "         5.3805e-02, -1.6619e-01], device='cuda:0')\n",
      "epoch_train_loss=50.437811464071274\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.768851034343243\n",
      "test_accuracy=0.0\n",
      "elapsed=8.762200117111206\n",
      "epoch=24\n",
      "predictions=tensor([-0.1023, -0.1404, -0.0817, -0.1091, -0.1106, -0.1571, -0.0878, -0.1512,\n",
      "        -0.1658, -0.1755, -0.1350, -0.1381, -0.1463, -0.1025, -0.1186, -0.1373,\n",
      "        -0.1119, -0.1727, -0.1123, -0.1392, -0.0887, -0.1252, -0.1424, -0.1125,\n",
      "        -0.1157, -0.1675, -0.1043, -0.1347, -0.1267, -0.1789, -0.1190, -0.1100],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3977, -0.9077, -0.4163, -0.0215, -0.2039, -0.3385,  0.9366,  0.0328,\n",
      "        -0.0013, -0.4119,  0.3597, -0.4964, -0.4498, -0.3078, -0.7436,  0.6186,\n",
      "         0.4341, -0.0077,  1.0932,  0.0686, -0.6556,  0.4048, -0.1383,  0.0510,\n",
      "        -0.8226, -0.7133,  0.2564, -0.3325,  0.1927, -0.4408, -0.5427, -0.1683],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.32818765193224\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.8351253271102905\n",
      "test_accuracy=0.0\n",
      "elapsed=8.8701753616333\n",
      "epoch=25\n",
      "predictions=tensor([-0.1285, -0.1085, -0.0391, -0.1044, -0.1257, -0.1073, -0.0953, -0.0877,\n",
      "        -0.0765, -0.0849, -0.1109, -0.0241, -0.1046, -0.0559, -0.1067, -0.1138,\n",
      "        -0.1601, -0.0939, -0.1013, -0.1202, -0.0725, -0.1373, -0.0334, -0.0552,\n",
      "        -0.0589, -0.0511, -0.0704, -0.0771, -0.1755, -0.1120, -0.0782, -0.1139],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.1602, -0.4136, -0.6244,  0.2326, -0.1216, -0.1913, -0.9514,  0.1298,\n",
      "        -0.4785,  0.2486, -0.6116,  0.1991, -0.1012, -0.4002, -0.4161, -0.0561,\n",
      "         0.3122, -0.1490,  0.6766, -0.4795,  0.3707,  0.0700, -0.1001, -0.1671,\n",
      "         0.3038, -0.6536, -0.7867, -0.5723, -0.0136, -0.1032, -0.6154, -0.0270],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.36830514296889\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.665634319186211\n",
      "test_accuracy=0.0\n",
      "elapsed=8.612432718276978\n",
      "epoch=26\n",
      "predictions=tensor([-0.1642, -0.1613, -0.1109, -0.1492, -0.1345, -0.1106, -0.1015, -0.1142,\n",
      "        -0.1296, -0.0714, -0.1109, -0.1136, -0.0857, -0.1344, -0.1065, -0.0824,\n",
      "        -0.1249, -0.1331, -0.1398, -0.1990, -0.0989, -0.1352, -0.1519, -0.1384,\n",
      "        -0.0801, -0.0423, -0.1157, -0.1352, -0.0928, -0.0289, -0.1412, -0.1019],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4946,  0.0866,  0.1579, -0.2195, -0.4109, -0.2511, -0.2515, -0.3460,\n",
      "         0.4349, -0.1540,  0.0627,  0.3687,  0.0435, -0.1538, -0.7489, -0.1319,\n",
      "         0.7510, -0.4976,  0.3070, -0.2210,  0.0064,  0.1867,  0.8522, -0.1626,\n",
      "         0.2448, -0.0736,  0.6453, -0.2814, -0.4531, -0.0802, -0.1165,  0.2037],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.40125884115696\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.697235584259033\n",
      "test_accuracy=0.0\n",
      "elapsed=8.656726360321045\n",
      "epoch=27\n",
      "predictions=tensor([-0.0951, -0.0692, -0.0257, -0.1426, -0.1008, -0.0834, -0.0432, -0.1073,\n",
      "        -0.0847, -0.1287, -0.0763, -0.0485, -0.0842, -0.0702, -0.0380, -0.1026,\n",
      "        -0.1161, -0.1223, -0.1098, -0.1009, -0.0775, -0.0462, -0.0870, -0.0823,\n",
      "        -0.0778, -0.1356, -0.1089, -0.1048, -0.0807, -0.0887, -0.1349, -0.1074],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2690, -0.0563, -0.1773, -0.0923, -0.2376, -0.6070,  0.1152, -0.6010,\n",
      "         0.9186, -0.9562,  0.3821,  0.3526,  0.1210, -0.6497, -0.5558, -0.5837,\n",
      "        -0.5308, -0.9649, -0.1433, -0.5915, -0.0398, -0.2906, -0.2308,  0.0813,\n",
      "        -0.1671, -0.3853, -0.5557, -0.7664, -0.3818, -0.0265,  0.0821, -0.2224],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.48068189620972\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.647832080721855\n",
      "test_accuracy=0.0\n",
      "elapsed=7.327750205993652\n",
      "epoch=28\n",
      "predictions=tensor([-0.1458, -0.1117, -0.1513, -0.1698, -0.0606, -0.1266, -0.1085, -0.1218,\n",
      "        -0.0662, -0.1397, -0.1757, -0.1662, -0.1166, -0.1502, -0.1223, -0.1089,\n",
      "        -0.1412, -0.1643, -0.1157, -0.1169, -0.1078, -0.1481, -0.0721, -0.1312,\n",
      "        -0.1083, -0.1744, -0.1607, -0.1891, -0.0651, -0.1083, -0.1215, -0.1272],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.4897,  0.1445, -0.2946,  0.4208, -0.4039, -0.0282, -0.0917,  0.2247,\n",
      "         0.0245,  0.0716,  0.2860, -0.4123, -0.2634, -0.0986,  0.0149, -0.5099,\n",
      "        -0.5537,  0.0435, -0.5166, -0.1435, -0.0963, -0.0329, -0.0022, -0.5829,\n",
      "        -0.1982, -0.3936,  0.4226, -0.5471,  0.1636, -0.4891, -0.0473,  0.6829],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.5438910163939\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.738177441060543\n",
      "test_accuracy=0.0\n",
      "elapsed=6.948552131652832\n",
      "epoch=29\n",
      "predictions=tensor([-0.0560, -0.0868, -0.1260, -0.0782, -0.1050, -0.0960, -0.1107, -0.0903,\n",
      "        -0.1400, -0.1134, -0.1382, -0.0657, -0.1119, -0.0886, -0.1205, -0.1342,\n",
      "        -0.1155, -0.1064, -0.1371, -0.1647, -0.1148, -0.1265, -0.1433, -0.1189,\n",
      "        -0.0899, -0.0657, -0.0835, -0.1546, -0.1542, -0.1012, -0.0694, -0.1379],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5549, -0.4674, -0.0092,  0.0987, -0.1293, -0.3841, -0.3801,  0.0514,\n",
      "        -0.1964, -0.0962, -0.4444,  0.6509,  0.1196,  0.1396, -0.0381,  0.0361,\n",
      "        -0.5534,  0.5185, -0.1919, -0.6851, -0.5460, -0.4478,  0.7053, -0.1700,\n",
      "        -0.0565, -0.2545, -0.3213, -0.6444, -0.6611,  0.6804,  0.8522,  0.3065],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.497349198907614\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.653636984527111\n",
      "test_accuracy=0.0\n",
      "elapsed=7.014325380325317\n",
      "epoch=30\n",
      "predictions=tensor([-0.1490, -0.0980, -0.1432, -0.1260, -0.1121, -0.1165, -0.1382, -0.1044,\n",
      "        -0.1522, -0.1304, -0.1669, -0.1346, -0.1236, -0.1066, -0.1362, -0.1276,\n",
      "        -0.1396, -0.2257, -0.0862, -0.1695, -0.1264, -0.1619, -0.1880, -0.1063,\n",
      "        -0.0929, -0.1099, -0.1340, -0.1805, -0.1206, -0.1645, -0.1268, -0.1235],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5006, -0.1770, -0.4526,  0.1396,  0.4528,  0.0541, -0.6836, -0.3804,\n",
      "        -0.0713,  0.4951,  0.3696, -0.3799,  0.0501, -0.5203,  0.1418, -0.4476,\n",
      "        -0.9250,  0.2831, -0.3832, -0.1825, -0.5032,  0.4009, -0.5208, -0.4339,\n",
      "        -0.1951, -0.6300, -0.0318, -0.6498,  0.2450, -0.4982,  0.4156,  0.0776],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.463774651288986\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.812802165746689\n",
      "test_accuracy=0.0\n",
      "elapsed=7.086624622344971\n",
      "epoch=31\n",
      "predictions=tensor([-0.1052, -0.0952, -0.0853, -0.0923, -0.1058, -0.1741, -0.0970, -0.1544,\n",
      "        -0.1439, -0.1232, -0.1391, -0.0928, -0.1043, -0.0771, -0.1208, -0.0979,\n",
      "        -0.0953, -0.1545, -0.1196, -0.1548, -0.0974, -0.1437, -0.1875, -0.0856,\n",
      "        -0.1543, -0.1043, -0.1633, -0.1321, -0.0776, -0.0838, -0.1052, -0.0989],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2446, -0.1538, -0.5054,  0.8382,  0.2129, -0.3669,  0.2280, -0.1490,\n",
      "         0.1950, -0.5108,  0.0143,  0.3970, -0.3064, -0.3046, -0.1581, -0.4806,\n",
      "        -0.4674,  0.0320, -0.5666, -0.4535,  0.1763, -0.4708,  0.5724,  0.0210,\n",
      "        -0.3294,  0.5530,  0.0984, -0.6316, -0.3743, -0.3660, -0.2424, -0.0709],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.6376270391047\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.7460286393761635\n",
      "test_accuracy=0.0\n",
      "elapsed=6.976657152175903\n",
      "epoch=32\n",
      "predictions=tensor([-0.1124, -0.1578, -0.0747, -0.0748, -0.1022, -0.0791, -0.0735, -0.1014,\n",
      "        -0.0815, -0.0965, -0.0658, -0.0558, -0.0652, -0.0727, -0.1373, -0.0793,\n",
      "        -0.0411, -0.0808, -0.0869, -0.0790, -0.1240, -0.1116, -0.1024, -0.0640,\n",
      "        -0.0340, -0.1173, -0.1291, -0.0620, -0.0634, -0.0830, -0.0591, -0.0992],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.5699, -0.0457, -0.3711, -0.0817,  0.0842, -0.3253,  0.3041, -0.4591,\n",
      "        -0.5308,  0.3560, -0.3544,  0.2912, -0.3228, -0.0731,  0.3257,  0.0052,\n",
      "        -0.9649, -0.3981,  0.4803,  0.1610, -0.3796,  0.3545,  0.0776,  0.1491,\n",
      "         0.4788, -0.3873, -0.1836, -0.1165, -0.4266, -0.7741,  0.0224, -0.2455],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.45658543333411\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.672922573983669\n",
      "test_accuracy=0.0\n",
      "elapsed=6.917897462844849\n",
      "epoch=33\n",
      "predictions=tensor([-0.1333, -0.1133, -0.1798, -0.1175, -0.1292, -0.1573, -0.1222, -0.1138,\n",
      "        -0.1167, -0.1383, -0.1551, -0.1542, -0.1516, -0.1284, -0.1438, -0.1300,\n",
      "        -0.0365, -0.1376, -0.1899, -0.0910, -0.1100, -0.1636, -0.1707, -0.1606,\n",
      "        -0.1472, -0.1195, -0.1881, -0.1679, -0.1306, -0.1259, -0.1078, -0.0872],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1054,  0.2297, -0.4027, -0.5203, -0.0905, -0.4523, -0.3392,  0.1584,\n",
      "        -0.6192,  0.0586, -0.0045, -0.2493,  0.0361,  0.1139,  0.1140, -0.3015,\n",
      "         0.3325, -0.0385,  0.0526,  0.0498,  0.0058,  0.3118, -0.1936,  0.2722,\n",
      "         0.2334, -0.3038,  0.2212, -0.4984, -0.6137,  0.3098, -0.3244, -0.4965],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.41308794170618\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.792661570012569\n",
      "test_accuracy=0.0\n",
      "elapsed=6.7090818881988525\n",
      "epoch=34\n",
      "predictions=tensor([-0.1389, -0.1139, -0.1907, -0.1870, -0.1899, -0.1645, -0.1155, -0.1301,\n",
      "        -0.1901, -0.1435, -0.1719, -0.1984, -0.1285, -0.1138, -0.1261, -0.0921,\n",
      "        -0.1167, -0.1397, -0.1446, -0.1393, -0.1367, -0.1453, -0.0975, -0.1636,\n",
      "        -0.1503, -0.1442, -0.1733, -0.1376, -0.1460, -0.1634, -0.1316, -0.1580],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3795, -0.1652, -0.3225, -0.3982,  0.7741, -0.4987,  0.0165,  0.4585,\n",
      "        -0.4372, -0.5921, -0.1561, -0.1935, -0.2869, -0.2101, -0.2670,  0.0279,\n",
      "        -0.4356, -0.5058, -0.3799, -0.3372, -0.1504, -0.4073,  0.6764,  0.1798,\n",
      "         1.0567, -0.4288,  0.3324,  0.0232, -0.2540, -0.3668, -0.3061,  0.1704],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.459425926208496\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.713170737028122\n",
      "test_accuracy=0.0\n",
      "elapsed=6.747661113739014\n",
      "epoch=35\n",
      "predictions=tensor([-0.0988, -0.1888, -0.1571, -0.0829, -0.1089, -0.1249, -0.0708, -0.1065,\n",
      "        -0.1241, -0.1149, -0.1394, -0.0854, -0.1380, -0.1639, -0.1435, -0.1032,\n",
      "        -0.1089, -0.0711, -0.1108, -0.0994, -0.1524, -0.1584, -0.1154, -0.1290,\n",
      "        -0.1141, -0.1311, -0.1032, -0.1717, -0.0768, -0.1508, -0.1617, -0.1035],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.3308,  0.3365, -0.0382, -0.1683,  0.2517,  0.9467, -0.5747, -0.3198,\n",
      "        -0.2333, -0.4213, -0.1662,  0.2713, -0.3426, -0.3784, -0.4411, -0.6073,\n",
      "         0.2292,  0.3325,  0.8656,  0.0017, -0.0402, -0.8236,  0.3302,  0.0710,\n",
      "         0.2342, -0.3678, -0.3849, -0.7943,  0.3165,  0.1063, -0.6836, -0.4868],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.3442368991673\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.728373304009438\n",
      "test_accuracy=0.0\n",
      "elapsed=6.8376288414001465\n",
      "epoch=36\n",
      "predictions=tensor([-0.0932, -0.1349, -0.0509, -0.1381, -0.1098, -0.1153, -0.0845, -0.0851,\n",
      "        -0.0876, -0.0971, -0.0829, -0.0968, -0.0716, -0.0401, -0.0842, -0.0970,\n",
      "        -0.1165, -0.0941, -0.0806, -0.1106, -0.0260, -0.1211, -0.1114, -0.0751,\n",
      "        -0.0552, -0.0783, -0.1164, -0.0790, -0.0847, -0.0689, -0.0683, -0.0763],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4669, -0.3754, -0.0728,  0.0534,  0.0477,  0.5328, -0.1877,  0.3968,\n",
      "         0.1228,  0.0118, -0.5383, -0.1127, -0.4919,  0.1007, -0.3509,  0.2736,\n",
      "         0.4496, -0.4216,  0.5449, -0.1016, -0.5524, -0.4021,  0.8421, -0.3488,\n",
      "        -0.0136, -0.2163,  0.2071, -0.4800,  0.4544, -0.1040,  1.0980, -0.0239],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.48936729878187\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.627006821334362\n",
      "test_accuracy=0.0\n",
      "elapsed=6.8674516677856445\n",
      "epoch=37\n",
      "predictions=tensor([-0.1266, -0.1408, -0.1456, -0.1535, -0.1645, -0.1187, -0.1195, -0.1507,\n",
      "        -0.0909, -0.1230, -0.1666, -0.1432, -0.1077, -0.1279, -0.0661, -0.1076,\n",
      "        -0.0899, -0.1189, -0.1572, -0.1410, -0.1823, -0.0584, -0.0841, -0.1653,\n",
      "        -0.1337, -0.1337, -0.1355, -0.1090, -0.1140, -0.1088, -0.1324, -0.0680],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-8.6341e-02, -3.5355e-01, -9.0460e-02, -1.4955e-01,  6.9115e-01,\n",
      "        -3.8195e-01,  2.2272e-01, -5.4505e-01, -8.5794e-01, -1.7050e-03,\n",
      "         4.1245e-01, -5.4665e-01, -4.4222e-01, -3.6454e-01,  5.4497e-01,\n",
      "        -8.3854e-01,  2.7861e-01, -1.4553e-02,  3.2625e-01, -3.8842e-01,\n",
      "        -2.0170e-01, -4.4785e-01, -5.0888e-01,  4.9541e-02,  1.8501e-01,\n",
      "         4.2411e-02, -3.6405e-01,  1.8373e+00, -2.5589e-01, -1.2841e-01,\n",
      "        -5.0907e-01,  7.1497e-01], device='cuda:0')\n",
      "epoch_train_loss=50.40413900837302\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.651494111865759\n",
      "test_accuracy=0.0\n",
      "elapsed=6.9433629512786865\n",
      "epoch=38\n",
      "predictions=tensor([-0.1540, -0.0855, -0.0844, -0.1186, -0.1232, -0.1367, -0.1195, -0.1205,\n",
      "        -0.1196, -0.1263, -0.1305, -0.0994, -0.1304, -0.0951, -0.0860, -0.1285,\n",
      "        -0.1646, -0.1364, -0.1228, -0.0946, -0.1233, -0.1225, -0.0822, -0.0844,\n",
      "        -0.1238, -0.1214, -0.1179, -0.1071, -0.1232, -0.1299, -0.1038, -0.1131],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2047, -0.3481,  0.1956, -0.2371,  0.0907, -0.0659,  0.0400,  0.0516,\n",
      "         0.2486, -0.1256, -0.1084, -0.3448, -0.5492, -0.3934,  0.0293, -0.2524,\n",
      "        -0.4537,  0.2068,  0.0823, -0.2957, -0.2362, -0.4041, -0.1427,  0.2521,\n",
      "        -0.4454,  0.5302,  0.1513,  0.3292,  0.5919, -0.4913, -0.4531, -0.1632],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.4118814393878\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.709757447242737\n",
      "test_accuracy=0.0\n",
      "elapsed=6.86184549331665\n",
      "epoch=39\n",
      "predictions=tensor([-0.1427, -0.0716, -0.0310, -0.0214, -0.1099, -0.1030, -0.0961, -0.0750,\n",
      "        -0.0680, -0.0666, -0.0516, -0.0811, -0.0458, -0.0464, -0.0874, -0.1141,\n",
      "        -0.0781, -0.1065, -0.0929, -0.0617, -0.0885, -0.1262, -0.1107, -0.0515,\n",
      "        -0.1007, -0.0585, -0.0805, -0.1328, -0.1100, -0.1143, -0.0954, -0.0944],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.3851, -0.1212, -0.1573, -0.3757, -0.3086, -0.1916, -0.6233, -0.1644,\n",
      "         0.0225, -0.2933,  0.2317, -0.1957,  0.2551, -0.2636, -0.0127,  0.0258,\n",
      "         0.3595, -0.4025, -0.4111, -0.1879,  0.0304, -0.0406, -0.1421,  0.1551,\n",
      "        -0.3965, -0.3081, -0.6354, -0.3011, -0.1347, -0.1859, -0.3315, -0.1040],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.414288870990276\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.659368060529232\n",
      "test_accuracy=0.0\n",
      "elapsed=6.8324151039123535\n",
      "epoch=40\n",
      "predictions=tensor([-0.0993, -0.1085, -0.0762, -0.1204, -0.0798, -0.1067, -0.0892, -0.1325,\n",
      "        -0.0943, -0.1050, -0.1601, -0.0661, -0.1126, -0.1154, -0.0916, -0.0385,\n",
      "        -0.0861, -0.0961, -0.1279, -0.1220, -0.0701, -0.1084, -0.0964, -0.0698,\n",
      "        -0.0770, -0.1293, -0.0810, -0.0910, -0.0813, -0.1051, -0.0959, -0.1240],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.0670, -0.3336, -0.1921, -0.1776,  0.2341,  0.5601,  0.2262, -0.2717,\n",
      "         0.1476, -0.3881,  0.6766, -0.1574, -0.5467, -0.2513, -0.1989,  0.5976,\n",
      "        -0.5788, -0.5337, -0.3424, -0.2761, -0.7011, -0.1738, -0.0112, -0.2037,\n",
      "        -0.5031, -0.2700, -0.2721, -0.2588, -0.3429,  0.0966,  0.1418,  0.1349],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.48463607951999\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.699892416596413\n",
      "test_accuracy=0.0\n",
      "elapsed=7.18135142326355\n",
      "epoch=41\n",
      "predictions=tensor([-0.0788, -0.1045, -0.1338, -0.1341, -0.0858, -0.1126, -0.0729, -0.1111,\n",
      "        -0.1371, -0.1533, -0.0901, -0.1763, -0.0835, -0.1473, -0.1047, -0.1481,\n",
      "        -0.1587, -0.0721, -0.1064, -0.0701, -0.1227, -0.0910, -0.1401, -0.0862,\n",
      "        -0.0985, -0.1315, -0.0948, -0.1101, -0.0788, -0.0460, -0.1297, -0.1488],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1725,  0.3522, -0.1293, -0.5447, -0.0883, -0.5247, -0.1811, -0.3368,\n",
      "        -0.2575, -0.4475, -0.4080,  0.5356, -0.4619,  0.5680, -0.3679, -0.1777,\n",
      "        -0.0543, -0.2747, -0.7062,  0.1508, -0.7403,  0.7182, -0.1659,  0.5091,\n",
      "        -0.1981, -0.0253, -0.0762,  0.2942, -0.2511, -0.3244, -0.5031, -0.3567],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.493594240397215\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.708501905202866\n",
      "test_accuracy=0.0\n",
      "elapsed=7.684690952301025\n",
      "epoch=42\n",
      "predictions=tensor([-0.1046, -0.1899, -0.1436, -0.1727, -0.1459, -0.1372, -0.1099, -0.2085,\n",
      "        -0.1464, -0.1607, -0.1280, -0.1891, -0.1581, -0.1598, -0.1590, -0.1590,\n",
      "        -0.1483, -0.1485, -0.2203, -0.1690, -0.1825, -0.1301, -0.1360, -0.1296,\n",
      "        -0.1554, -0.1500, -0.1501, -0.1512, -0.1912, -0.1758, -0.1986, -0.1285],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4426, -0.4164, -0.0590, -0.0977, -0.2223,  0.5288, -0.4254, -0.2545,\n",
      "        -0.0032,  0.1392, -0.1797, -0.8543, -0.0898,  0.1935, -0.6633, -0.3945,\n",
      "        -0.8581, -0.1375,  0.0435, -0.0633,  0.4769, -0.1784, -0.3011, -0.0182,\n",
      "         0.1648, -0.6027, -0.5670, -0.0450, -0.5248,  0.7276,  0.1730,  1.4115],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.44951003044844\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=6.021906465291977\n",
      "test_accuracy=0.0\n",
      "elapsed=6.949227571487427\n",
      "epoch=43\n",
      "predictions=tensor([-0.1495, -0.0957, -0.0399, -0.1159, -0.0773, -0.0905, -0.1385, -0.0906,\n",
      "        -0.0497, -0.1081, -0.1085, -0.1113, -0.0841, -0.0631, -0.0990, -0.1322,\n",
      "        -0.1548, -0.1317, -0.1212, -0.0942, -0.1041, -0.1197, -0.1300, -0.1424,\n",
      "        -0.1355, -0.1264, -0.0994, -0.0635, -0.1064, -0.1156, -0.1016, -0.1267],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2267, -0.6407, -0.7864, -0.2054,  0.7276, -0.0941,  0.1965,  0.1594,\n",
      "        -0.3244, -0.4486, -0.0358, -0.2889,  0.4288,  0.0830, -0.5408,  0.0427,\n",
      "         0.5064, -0.2907, -0.5074,  0.0268,  0.0946, -0.4084, -0.0097, -0.2313,\n",
      "         0.1658, -0.1273, -0.3078,  0.4344, -0.0095,  0.4095, -0.8667,  0.1580],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.40806893631816\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.71856003254652\n",
      "test_accuracy=0.0\n",
      "elapsed=6.789422035217285\n",
      "epoch=44\n",
      "predictions=tensor([-0.1431, -0.1138, -0.0408, -0.1204, -0.1532, -0.1377, -0.1254, -0.0555,\n",
      "        -0.1500, -0.1779, -0.1488, -0.1411, -0.0880, -0.1806, -0.0925, -0.1470,\n",
      "        -0.0348, -0.1433, -0.1218, -0.1351, -0.1370, -0.1431, -0.1225, -0.1237,\n",
      "        -0.1036, -0.1480, -0.1254, -0.0954, -0.1061, -0.1553, -0.1276, -0.0899],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.0824,  0.1117, -0.4282, -0.5323, -0.4366, -0.2290,  0.2474, -0.2046,\n",
      "        -0.1641, -0.4234, -0.2252,  0.1554,  0.4159, -0.9434,  0.1492, -0.1557,\n",
      "         0.1314, -0.0965, -0.5427, -0.3873, -0.2624, -0.1445, -0.5061,  0.0114,\n",
      "        -0.0984,  0.3687, -0.2267, -0.5394, -0.2411,  0.2051, -0.4333, -0.1741],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.25693175941706\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.743016302585602\n",
      "test_accuracy=0.0\n",
      "elapsed=6.868554592132568\n",
      "epoch=45\n",
      "predictions=tensor([-0.1696, -0.1541, -0.2216, -0.1246, -0.1137, -0.1273, -0.1816, -0.1477,\n",
      "        -0.1484, -0.1232, -0.1211, -0.1184, -0.1783, -0.1172, -0.1990, -0.1534,\n",
      "        -0.1400, -0.1352, -0.1542, -0.1588, -0.1283, -0.1364, -0.1222, -0.1405,\n",
      "        -0.1491, -0.1415, -0.1455, -0.1068, -0.1337, -0.1365, -0.1122, -0.1589],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.1932, -0.6347, -0.3969,  0.3519, -0.2667, -0.4795,  0.2351, -0.0678,\n",
      "         0.3970,  0.5867,  0.5432, -0.6032, -0.4292, -0.3158,  0.5723, -0.1585,\n",
      "         0.4608,  1.0708,  0.1300, -0.2108, -0.2254, -0.2892,  0.0653, -0.4843,\n",
      "         0.9557, -0.1643, -0.2374, -0.0954, -0.2487, -0.4216, -0.7741,  0.0446],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.44596856459975\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.798339307308197\n",
      "test_accuracy=0.0\n",
      "elapsed=6.892341375350952\n",
      "epoch=46\n",
      "predictions=tensor([-0.1452, -0.1532, -0.1343, -0.1526, -0.1312, -0.1411, -0.1637, -0.1400,\n",
      "        -0.1397, -0.1406, -0.1561, -0.1153, -0.1090, -0.1002, -0.1553, -0.1119,\n",
      "        -0.2019, -0.1427, -0.1505, -0.1145, -0.1178, -0.1556, -0.1092, -0.1691,\n",
      "        -0.0833, -0.1546, -0.1570, -0.1298, -0.1410, -0.1500, -0.1193, -0.0702],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.5932, -0.1052, -0.1434,  0.0178,  0.3103, -0.2218, -0.3225,  0.1817,\n",
      "         0.1947, -0.1633, -0.3983, -0.2820, -0.3914, -0.1034, -0.5082, -0.4091,\n",
      "        -0.2373,  0.0458, -0.2334, -0.1934,  0.0502, -0.4547, -0.1479, -0.2219,\n",
      "         0.1484, -0.3918, -0.2404, -0.3731, -0.5088,  0.1565, -0.1820, -0.1508],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.52710387855768\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.749047234654427\n",
      "test_accuracy=0.0\n",
      "elapsed=6.9356489181518555\n",
      "epoch=47\n",
      "predictions=tensor([-0.0901, -0.0514, -0.0774, -0.0993, -0.1602, -0.1120, -0.1154, -0.0893,\n",
      "        -0.0831, -0.0567, -0.1062, -0.1002, -0.1004, -0.0974, -0.1076, -0.1096,\n",
      "        -0.0880, -0.1055, -0.0992, -0.1041, -0.1207, -0.0840, -0.0410, -0.0758,\n",
      "        -0.0233, -0.1570, -0.0750, -0.1066, -0.0740, -0.0913, -0.0814, -0.1321],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.4218, -0.0771,  0.0724, -0.1967, -0.0693,  0.7557, -0.4976,  0.1345,\n",
      "         0.1289, -0.2654, -0.4756, -0.6871, -0.0841, -0.4261, -0.3688, -0.5835,\n",
      "         0.2027, -0.2971, -0.1215,  0.3535,  0.0591, -0.0912, -0.4959, -0.2333,\n",
      "        -0.2555, -0.3673,  0.3391, -0.3633, -0.1745, -0.3881,  0.2630, -0.4721],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.30201255902648\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.70118148624897\n",
      "test_accuracy=0.0\n",
      "elapsed=7.065890073776245\n",
      "epoch=48\n",
      "predictions=tensor([-0.1494, -0.0823, -0.1078, -0.1331, -0.1014, -0.1240, -0.1208, -0.0950,\n",
      "        -0.0924, -0.1022, -0.0807, -0.1773, -0.1114, -0.1299, -0.1292, -0.1182,\n",
      "        -0.1112, -0.1232, -0.1366, -0.1137, -0.1399, -0.1300, -0.1277, -0.0811,\n",
      "        -0.1402, -0.0635, -0.1101, -0.1468, -0.0680, -0.1111, -0.1687, -0.1234],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([ 0.0238,  0.9498,  0.1546, -0.0334, -0.3919, -0.0707,  0.1210, -0.1266,\n",
      "         0.2443,  0.6219,  0.7126,  0.3032, -0.2501,  0.3828,  0.0909,  0.4196,\n",
      "        -0.1728, -0.6019, -0.4175, -0.4982, -0.2796, -0.3051,  0.4612,  0.0412,\n",
      "         0.4394,  0.4492, -0.5228, -0.2725,  0.1043, -0.4611,  0.2801, -0.2318],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.29571709036827\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.647445864975452\n",
      "test_accuracy=0.0\n",
      "elapsed=7.000643014907837\n",
      "epoch=49\n",
      "predictions=tensor([-0.1169, -0.1661, -0.1463, -0.1676, -0.1016, -0.1804, -0.1607, -0.1706,\n",
      "        -0.1727, -0.0736, -0.1351, -0.1209, -0.1449, -0.1333, -0.2076, -0.1612,\n",
      "        -0.1671, -0.1367, -0.1120, -0.1282, -0.1109, -0.0902, -0.1420, -0.1297,\n",
      "        -0.1560, -0.1483, -0.1023, -0.1588, -0.1736, -0.1363, -0.1654, -0.0897],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.2613, -0.3415, -0.2562, -0.1174,  0.1604, -0.5306, -0.0053,  0.3212,\n",
      "         0.0877, -0.3218, -0.2506,  0.2991, -0.1973, -0.4302, -0.3607, -0.0746,\n",
      "         0.1202,  0.2976, -0.4248, -0.1062,  0.0109, -0.3642,  0.0240,  0.0502,\n",
      "        -0.1859, -0.0203, -0.3277, -0.4032, -0.7154,  0.0014, -0.1791,  1.2542],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.42862804979086\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.719333842396736\n",
      "test_accuracy=0.0\n",
      "elapsed=7.023165464401245\n",
      "epoch=50\n",
      "predictions=tensor([-0.0965, -0.0756, -0.1024, -0.0919, -0.0962, -0.1318, -0.1506, -0.0603,\n",
      "        -0.0586, -0.0390, -0.1034, -0.0414, -0.0906, -0.1532, -0.0453, -0.1254,\n",
      "        -0.0681, -0.0574, -0.0557, -0.1102, -0.0710, -0.1066, -0.0805, -0.0979,\n",
      "        -0.0795, -0.0692, -0.0710, -0.1216, -0.0565, -0.0858, -0.1060, -0.1468],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward1>) | scores=tensor([-0.4853, -0.2591, -0.3983, -0.2829,  0.5100, -0.3460, -0.4037, -0.4964,\n",
      "        -0.0122, -0.2667, -0.0144, -0.8294, -0.1460, -0.1161,  0.0073,  0.0281,\n",
      "        -0.0163, -0.2051,  0.2231,  0.1225,  0.4666, -0.2318, -0.5090, -0.2562,\n",
      "         0.2869,  0.5209,  0.9467, -0.3511, -0.3553, -0.6329, -0.6906, -0.0342],\n",
      "       device='cuda:0')\n",
      "epoch_train_loss=50.30224095284939\n",
      "train_accuracy=0.0\n",
      "epoch_test_loss=5.701411731541157\n",
      "test_accuracy=0.0\n",
      "elapsed=6.98108696937561\n"
     ]
    }
   ],
   "source": [
    "#train the model!\n",
    "epochs = 50\n",
    "\n",
    "print(\"starting\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    print(f\"{epoch=}\")\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    evaluate(model)\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print(f\"{elapsed=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "\n",
    "train_iter = iter(IMDB(split='train'))\n",
    "next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : torch.Size([32])\n",
      "1 : torch.Size([32])\n",
      "2 : torch.Size([32])\n",
      "3 : torch.Size([32])\n",
      "4 : torch.Size([32])\n",
      "5 : torch.Size([32])\n",
      "6 : torch.Size([32])\n",
      "7 : torch.Size([32])\n",
      "8 : torch.Size([32])\n",
      "9 : torch.Size([32])\n",
      "10 : torch.Size([32])\n",
      "11 : torch.Size([32])\n",
      "12 : torch.Size([32])\n",
      "13 : torch.Size([32])\n",
      "14 : torch.Size([32])\n",
      "15 : torch.Size([32])\n",
      "16 : torch.Size([32])\n",
      "17 : torch.Size([32])\n",
      "18 : torch.Size([32])\n",
      "19 : torch.Size([32])\n",
      "20 : torch.Size([32])\n",
      "21 : torch.Size([32])\n",
      "22 : torch.Size([32])\n",
      "23 : torch.Size([32])\n",
      "24 : torch.Size([32])\n",
      "25 : torch.Size([32])\n",
      "26 : torch.Size([32])\n",
      "27 : torch.Size([32])\n",
      "28 : torch.Size([32])\n",
      "29 : torch.Size([32])\n",
      "30 : torch.Size([32])\n",
      "31 : torch.Size([32])\n",
      "32 : torch.Size([32])\n",
      "33 : torch.Size([32])\n",
      "34 : torch.Size([32])\n",
      "35 : torch.Size([32])\n",
      "36 : torch.Size([32])\n",
      "37 : torch.Size([32])\n",
      "38 : torch.Size([32])\n",
      "39 : torch.Size([32])\n",
      "40 : torch.Size([32])\n",
      "41 : torch.Size([32])\n",
      "42 : torch.Size([32])\n",
      "43 : torch.Size([32])\n",
      "44 : torch.Size([32])\n",
      "45 : torch.Size([32])\n",
      "46 : torch.Size([32])\n",
      "47 : torch.Size([32])\n",
      "48 : torch.Size([32])\n",
      "49 : torch.Size([32])\n",
      "50 : torch.Size([32])\n",
      "51 : torch.Size([32])\n",
      "52 : torch.Size([32])\n",
      "53 : torch.Size([32])\n",
      "54 : torch.Size([32])\n",
      "55 : torch.Size([32])\n",
      "56 : torch.Size([32])\n",
      "57 : torch.Size([32])\n",
      "58 : torch.Size([32])\n",
      "59 : torch.Size([32])\n",
      "60 : torch.Size([32])\n",
      "61 : torch.Size([32])\n",
      "62 : torch.Size([32])\n",
      "63 : torch.Size([32])\n",
      "64 : torch.Size([32])\n",
      "65 : torch.Size([32])\n",
      "66 : torch.Size([32])\n",
      "67 : torch.Size([32])\n",
      "68 : torch.Size([32])\n",
      "69 : torch.Size([32])\n",
      "70 : torch.Size([32])\n",
      "71 : torch.Size([32])\n",
      "72 : torch.Size([32])\n",
      "73 : torch.Size([32])\n",
      "74 : torch.Size([32])\n",
      "75 : torch.Size([32])\n",
      "76 : torch.Size([32])\n",
      "77 : torch.Size([32])\n",
      "78 : torch.Size([32])\n",
      "79 : torch.Size([32])\n",
      "80 : torch.Size([32])\n",
      "81 : torch.Size([32])\n",
      "82 : torch.Size([32])\n",
      "83 : torch.Size([32])\n",
      "84 : torch.Size([32])\n",
      "85 : torch.Size([32])\n",
      "86 : torch.Size([32])\n",
      "87 : torch.Size([32])\n",
      "88 : torch.Size([32])\n",
      "89 : torch.Size([32])\n",
      "90 : torch.Size([32])\n",
      "91 : torch.Size([32])\n",
      "92 : torch.Size([32])\n",
      "93 : torch.Size([32])\n",
      "94 : torch.Size([32])\n",
      "95 : torch.Size([32])\n",
      "96 : torch.Size([32])\n",
      "97 : torch.Size([32])\n",
      "98 : torch.Size([32])\n",
      "99 : torch.Size([32])\n",
      "100 : torch.Size([32])\n",
      "101 : torch.Size([32])\n",
      "102 : torch.Size([32])\n",
      "103 : torch.Size([32])\n",
      "104 : torch.Size([32])\n",
      "105 : torch.Size([32])\n",
      "106 : torch.Size([32])\n",
      "107 : torch.Size([32])\n",
      "108 : torch.Size([32])\n",
      "109 : torch.Size([32])\n",
      "110 : torch.Size([32])\n",
      "111 : torch.Size([32])\n",
      "112 : torch.Size([32])\n",
      "113 : torch.Size([32])\n",
      "114 : torch.Size([32])\n",
      "115 : torch.Size([32])\n",
      "116 : torch.Size([32])\n",
      "117 : torch.Size([32])\n",
      "118 : torch.Size([32])\n",
      "119 : torch.Size([32])\n",
      "120 : torch.Size([32])\n",
      "121 : torch.Size([32])\n",
      "122 : torch.Size([32])\n",
      "123 : torch.Size([32])\n",
      "124 : torch.Size([32])\n",
      "125 : torch.Size([32])\n",
      "126 : torch.Size([32])\n",
      "127 : torch.Size([32])\n",
      "128 : torch.Size([32])\n",
      "129 : torch.Size([32])\n",
      "130 : torch.Size([32])\n",
      "131 : torch.Size([32])\n",
      "132 : torch.Size([32])\n",
      "133 : torch.Size([32])\n",
      "134 : torch.Size([32])\n",
      "135 : torch.Size([32])\n",
      "136 : torch.Size([32])\n",
      "137 : torch.Size([32])\n",
      "138 : torch.Size([32])\n",
      "139 : torch.Size([32])\n",
      "140 : torch.Size([32])\n",
      "141 : torch.Size([32])\n",
      "142 : torch.Size([32])\n",
      "143 : torch.Size([32])\n",
      "144 : torch.Size([32])\n",
      "145 : torch.Size([32])\n",
      "146 : torch.Size([32])\n",
      "147 : torch.Size([32])\n",
      "148 : torch.Size([32])\n",
      "149 : torch.Size([32])\n",
      "150 : torch.Size([32])\n",
      "151 : torch.Size([32])\n",
      "152 : torch.Size([32])\n",
      "153 : torch.Size([32])\n",
      "154 : torch.Size([32])\n",
      "155 : torch.Size([32])\n",
      "156 : torch.Size([32])\n",
      "157 : torch.Size([32])\n",
      "158 : torch.Size([32])\n",
      "159 : torch.Size([32])\n",
      "160 : torch.Size([32])\n",
      "161 : torch.Size([32])\n",
      "162 : torch.Size([32])\n",
      "163 : torch.Size([32])\n",
      "164 : torch.Size([32])\n",
      "165 : torch.Size([32])\n",
      "166 : torch.Size([32])\n",
      "167 : torch.Size([32])\n",
      "168 : torch.Size([32])\n",
      "169 : torch.Size([32])\n",
      "170 : torch.Size([32])\n",
      "171 : torch.Size([32])\n",
      "172 : torch.Size([32])\n",
      "173 : torch.Size([32])\n",
      "174 : torch.Size([32])\n",
      "175 : torch.Size([32])\n",
      "176 : torch.Size([32])\n",
      "177 : torch.Size([32])\n",
      "178 : torch.Size([32])\n",
      "179 : torch.Size([32])\n",
      "180 : torch.Size([32])\n",
      "181 : torch.Size([32])\n",
      "182 : torch.Size([32])\n",
      "183 : torch.Size([32])\n",
      "184 : torch.Size([32])\n",
      "185 : torch.Size([32])\n",
      "186 : torch.Size([32])\n",
      "187 : torch.Size([32])\n",
      "188 : torch.Size([32])\n",
      "189 : torch.Size([32])\n",
      "190 : torch.Size([32])\n",
      "191 : torch.Size([32])\n",
      "192 : torch.Size([32])\n",
      "193 : torch.Size([32])\n",
      "194 : torch.Size([32])\n",
      "195 : torch.Size([32])\n",
      "196 : torch.Size([32])\n",
      "197 : torch.Size([32])\n",
      "198 : torch.Size([32])\n",
      "199 : torch.Size([32])\n",
      "200 : torch.Size([32])\n",
      "201 : torch.Size([32])\n",
      "202 : torch.Size([32])\n",
      "203 : torch.Size([32])\n",
      "204 : torch.Size([32])\n",
      "205 : torch.Size([32])\n",
      "206 : torch.Size([32])\n",
      "207 : torch.Size([32])\n",
      "208 : torch.Size([32])\n",
      "209 : torch.Size([32])\n",
      "210 : torch.Size([32])\n",
      "211 : torch.Size([32])\n",
      "212 : torch.Size([32])\n",
      "213 : torch.Size([32])\n",
      "214 : torch.Size([32])\n",
      "215 : torch.Size([32])\n",
      "216 : torch.Size([32])\n",
      "217 : torch.Size([32])\n",
      "218 : torch.Size([32])\n",
      "219 : torch.Size([32])\n",
      "220 : torch.Size([32])\n",
      "221 : torch.Size([32])\n",
      "222 : torch.Size([32])\n",
      "223 : torch.Size([32])\n",
      "224 : torch.Size([32])\n",
      "225 : torch.Size([32])\n",
      "226 : torch.Size([32])\n",
      "227 : torch.Size([32])\n",
      "228 : torch.Size([32])\n",
      "229 : torch.Size([32])\n",
      "230 : torch.Size([32])\n",
      "231 : torch.Size([32])\n",
      "232 : torch.Size([32])\n",
      "233 : torch.Size([32])\n",
      "234 : torch.Size([32])\n",
      "235 : torch.Size([32])\n",
      "236 : torch.Size([32])\n",
      "237 : torch.Size([32])\n",
      "238 : torch.Size([32])\n",
      "239 : torch.Size([32])\n",
      "240 : torch.Size([32])\n",
      "241 : torch.Size([32])\n",
      "242 : torch.Size([32])\n",
      "243 : torch.Size([32])\n",
      "244 : torch.Size([32])\n",
      "245 : torch.Size([32])\n",
      "246 : torch.Size([32])\n",
      "247 : torch.Size([32])\n",
      "248 : torch.Size([32])\n",
      "249 : torch.Size([32])\n",
      "250 : torch.Size([32])\n",
      "251 : torch.Size([32])\n",
      "252 : torch.Size([32])\n",
      "253 : torch.Size([32])\n",
      "254 : torch.Size([32])\n",
      "255 : torch.Size([32])\n",
      "256 : torch.Size([32])\n",
      "257 : torch.Size([32])\n",
      "258 : torch.Size([32])\n",
      "259 : torch.Size([32])\n",
      "260 : torch.Size([32])\n",
      "261 : torch.Size([32])\n",
      "262 : torch.Size([32])\n",
      "263 : torch.Size([32])\n",
      "264 : torch.Size([32])\n",
      "265 : torch.Size([32])\n",
      "266 : torch.Size([32])\n",
      "267 : torch.Size([32])\n",
      "268 : torch.Size([32])\n",
      "269 : torch.Size([32])\n",
      "270 : torch.Size([32])\n",
      "271 : torch.Size([32])\n",
      "272 : torch.Size([32])\n",
      "273 : torch.Size([32])\n",
      "274 : torch.Size([32])\n",
      "275 : torch.Size([32])\n",
      "276 : torch.Size([32])\n",
      "277 : torch.Size([32])\n",
      "278 : torch.Size([32])\n",
      "279 : torch.Size([32])\n",
      "280 : torch.Size([32])\n",
      "281 : torch.Size([32])\n",
      "282 : torch.Size([32])\n",
      "283 : torch.Size([32])\n",
      "284 : torch.Size([32])\n",
      "285 : torch.Size([32])\n",
      "286 : torch.Size([32])\n",
      "287 : torch.Size([32])\n",
      "288 : torch.Size([32])\n",
      "289 : torch.Size([32])\n",
      "290 : torch.Size([32])\n",
      "291 : torch.Size([32])\n",
      "292 : torch.Size([32])\n",
      "293 : torch.Size([32])\n",
      "294 : torch.Size([32])\n",
      "295 : torch.Size([32])\n",
      "296 : torch.Size([32])\n",
      "297 : torch.Size([32])\n",
      "298 : torch.Size([32])\n",
      "299 : torch.Size([32])\n",
      "300 : torch.Size([32])\n",
      "301 : torch.Size([32])\n",
      "302 : torch.Size([32])\n",
      "303 : torch.Size([32])\n",
      "304 : torch.Size([32])\n",
      "305 : torch.Size([32])\n",
      "306 : torch.Size([32])\n",
      "307 : torch.Size([32])\n",
      "308 : torch.Size([32])\n",
      "309 : torch.Size([32])\n",
      "310 : torch.Size([32])\n",
      "311 : torch.Size([32])\n",
      "312 : torch.Size([32])\n",
      "313 : torch.Size([32])\n",
      "314 : torch.Size([32])\n",
      "315 : torch.Size([32])\n",
      "316 : torch.Size([32])\n",
      "317 : torch.Size([32])\n",
      "318 : torch.Size([32])\n",
      "319 : torch.Size([32])\n",
      "320 : torch.Size([32])\n",
      "321 : torch.Size([32])\n",
      "322 : torch.Size([32])\n",
      "323 : torch.Size([32])\n",
      "324 : torch.Size([32])\n",
      "325 : torch.Size([32])\n",
      "326 : torch.Size([32])\n",
      "327 : torch.Size([32])\n",
      "328 : torch.Size([32])\n",
      "329 : torch.Size([32])\n",
      "330 : torch.Size([32])\n",
      "331 : torch.Size([32])\n",
      "332 : torch.Size([32])\n",
      "333 : torch.Size([32])\n",
      "334 : torch.Size([32])\n",
      "335 : torch.Size([32])\n",
      "336 : torch.Size([32])\n",
      "337 : torch.Size([32])\n",
      "338 : torch.Size([32])\n",
      "339 : torch.Size([32])\n",
      "340 : torch.Size([32])\n",
      "341 : torch.Size([32])\n",
      "342 : torch.Size([32])\n",
      "343 : torch.Size([32])\n",
      "344 : torch.Size([32])\n",
      "345 : torch.Size([32])\n",
      "346 : torch.Size([32])\n",
      "347 : torch.Size([32])\n",
      "348 : torch.Size([32])\n",
      "349 : torch.Size([32])\n",
      "350 : torch.Size([24])\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(iter(train_loader)):\n",
    "   print(idx, \":\", batch[1].size())\n",
    "\n",
    "#for target in next(iter(train_loader))[1]:\n",
    "#    print(target.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
